{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SleepDataPreparation_and_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeonggunlee/SleepCapstone/blob/master/Codes/SleepNet_with_Convolution_3stage_Conv_LeakyRELU_80_35.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAGJRSb3xOT1"
      },
      "source": [
        "한림대학교 소프트웨어 융합대학\n",
        "빅데이터 캡스톤 프로젝트\n",
        "\n",
        "딥러닝에 기반한 수면 분류 모델 개발"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SaQVdPHgfmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1bb0a0-d573-438f-d0a7-bba8937165b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohoEZomKw0cz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a52240-64e6-4dd3-8152-25d6b55e511e"
      },
      "source": [
        "cd drive/My\\ Drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvna-5vRzmTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ceb227c-38a8-409d-cabb-7ceb4beed8b8"
      },
      "source": [
        "# GPU 가용성 체크\n",
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Nov 24 07:59:49 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1zNHBNc4beq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def search_signals_npy(dirname):\n",
        "    filenames = os.listdir(dirname)\n",
        "    filenames = [file for file in filenames if file.endswith(\".npy\")]\n",
        "    return filenames\n",
        "\n",
        "def search_correct_signals_npy(dirname,filename):\n",
        "    search_filename = filename.split('-')[0][:-2]\n",
        "    file_list = os.listdir(dirname)\n",
        "    filename = [file for file in file_list if search_filename in file if file.endswith(\"npy\")]\n",
        "    \n",
        "    return filename"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vSGY6sO9vgC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "df52dd7d-2043-4284-c411-b18264340a33"
      },
      "source": [
        "\n",
        "fs = 100                                # Sampling rate (512 Hz)\n",
        "epoch_size = 30\n",
        "#data = np.random.uniform(0, 100, 1024)  # 2 sec of data b/w 0.0-100.0\n",
        "\n",
        "path =  'annotations/npy/remove_wake/'\n",
        "signals_path = 'signals/npy/Fpz-Cz/remove_wake/'\n",
        "\n",
        "annotations_npy_list = search_signals_npy(path)\n",
        "\n",
        "total_label = np.zeros([6],dtype=int)\n",
        "\n",
        "for filename in annotations_npy_list:\n",
        "    label = np.load(path + filename)\n",
        "    signals_filename = search_correct_signals_npy(signals_path,filename)[0]\n",
        "    \n",
        "    signals = np.load(signals_path+signals_filename)\n",
        "    \n",
        "    #print('remove start index : %d / remove end index : %d'%(remove_start_index,remove_end_index))\n",
        "    #print(np.bincount(label,minlength=6))\n",
        "    if len(label) !=len(signals[0])//30//fs:\n",
        "        print('file is fault!!!')\n",
        "    for i in range(6):\n",
        "        total_label[i] += np.bincount(label,minlength=6)[i]\n",
        "        \n",
        "print(total_label)\n",
        "\n",
        "x = np.arange(len(total_label))\n",
        "\n",
        "plt.bar(x,total_label,width=0.7)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 4336  2804 17799  5703  7717    61]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 6 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVVZuGLx-ADW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72196dc4-a254-44db-8b8b-eeefb1b0b1c7"
      },
      "source": [
        "fs = 100                                # Sampling rate (512 Hz)\n",
        "epoch_size = 30\n",
        "#data = np.random.uniform(0, 100, 1024)  # 2 sec of data b/w 0.0-100.0\n",
        "\n",
        "path =  'annotations/npy/remove_wake/'\n",
        "signals_path = 'signals/npy/Fpz-Cz/remove_wake/'\n",
        "\n",
        "annotations_npy_list = search_signals_npy(path)\n",
        "\n",
        "print(annotations_npy_list)\n",
        "\n",
        "random.shuffle(annotations_npy_list)\n",
        "\n",
        "print(annotations_npy_list)\n",
        "\n",
        "trainDataset_count = 30\n",
        "testDataset_count = len(annotations_npy_list)-trainDataset_count\n",
        "\n",
        "train_label = np.zeros([6],dtype=int)\n",
        "test_label = np.zeros([6],dtype=int)\n",
        "\n",
        "for filename in annotations_npy_list[:trainDataset_count]:\n",
        "    label = np.load(path + filename)\n",
        "    \n",
        "    for i in range(6):\n",
        "        train_label[i] += np.bincount(label,minlength=6)[i]\n",
        "\n",
        "        \n",
        "for filename in annotations_npy_list[trainDataset_count:]:\n",
        "    label = np.load(path + filename)\n",
        "    \n",
        "    for i in range(6):\n",
        "        test_label[i] += np.bincount(label,minlength=6)[i]\n",
        "        \n",
        "train_label = train_label / np.sum(train_label) * 100\n",
        "test_label = test_label / np.sum(test_label) * 100\n",
        "print(train_label)\n",
        "print(test_label)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SC4001EC-Hypnogram.npy', 'SC4002EC-Hypnogram.npy', 'SC4011EH-Hypnogram.npy', 'SC4012EC-Hypnogram.npy', 'SC4021EH-Hypnogram.npy', 'SC4022EJ-Hypnogram.npy', 'SC4031EC-Hypnogram.npy', 'SC4032EP-Hypnogram.npy', 'SC4041EC-Hypnogram.npy', 'SC4042EC-Hypnogram.npy', 'SC4051EC-Hypnogram.npy', 'SC4052EC-Hypnogram.npy', 'SC4061EC-Hypnogram.npy', 'SC4062EC-Hypnogram.npy', 'SC4071EC-Hypnogram.npy', 'SC4072EH-Hypnogram.npy', 'SC4081EC-Hypnogram.npy', 'SC4082EP-Hypnogram.npy', 'SC4091EC-Hypnogram.npy', 'SC4092EC-Hypnogram.npy', 'SC4101EC-Hypnogram.npy', 'SC4102EC-Hypnogram.npy', 'SC4111EC-Hypnogram.npy', 'SC4112EC-Hypnogram.npy', 'SC4121EC-Hypnogram.npy', 'SC4122EV-Hypnogram.npy', 'SC4131EC-Hypnogram.npy', 'SC4141EU-Hypnogram.npy', 'SC4142EU-Hypnogram.npy', 'SC4151EC-Hypnogram.npy', 'SC4152EC-Hypnogram.npy', 'SC4161EC-Hypnogram.npy', 'SC4162EC-Hypnogram.npy', 'SC4171EU-Hypnogram.npy', 'SC4172EC-Hypnogram.npy', 'SC4181EC-Hypnogram.npy', 'SC4182EC-Hypnogram.npy', 'SC4191EP-Hypnogram.npy', 'SC4192EV-Hypnogram.npy']\n",
            "['SC4092EC-Hypnogram.npy', 'SC4102EC-Hypnogram.npy', 'SC4161EC-Hypnogram.npy', 'SC4191EP-Hypnogram.npy', 'SC4152EC-Hypnogram.npy', 'SC4171EU-Hypnogram.npy', 'SC4032EP-Hypnogram.npy', 'SC4121EC-Hypnogram.npy', 'SC4131EC-Hypnogram.npy', 'SC4162EC-Hypnogram.npy', 'SC4031EC-Hypnogram.npy', 'SC4012EC-Hypnogram.npy', 'SC4001EC-Hypnogram.npy', 'SC4111EC-Hypnogram.npy', 'SC4192EV-Hypnogram.npy', 'SC4042EC-Hypnogram.npy', 'SC4181EC-Hypnogram.npy', 'SC4101EC-Hypnogram.npy', 'SC4041EC-Hypnogram.npy', 'SC4172EC-Hypnogram.npy', 'SC4072EH-Hypnogram.npy', 'SC4112EC-Hypnogram.npy', 'SC4011EH-Hypnogram.npy', 'SC4052EC-Hypnogram.npy', 'SC4062EC-Hypnogram.npy', 'SC4061EC-Hypnogram.npy', 'SC4182EC-Hypnogram.npy', 'SC4141EU-Hypnogram.npy', 'SC4022EJ-Hypnogram.npy', 'SC4081EC-Hypnogram.npy', 'SC4002EC-Hypnogram.npy', 'SC4151EC-Hypnogram.npy', 'SC4142EU-Hypnogram.npy', 'SC4091EC-Hypnogram.npy', 'SC4122EV-Hypnogram.npy', 'SC4071EC-Hypnogram.npy', 'SC4021EH-Hypnogram.npy', 'SC4082EP-Hypnogram.npy', 'SC4051EC-Hypnogram.npy']\n",
            "[12.0377061   7.45910793 47.11292124 13.66353544 19.57892662  0.14780267]\n",
            "[ 8.41484826  6.68422373 43.32831703 19.35038876 22.0215701   0.20065212]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAKH9Mb0_NF3",
        "outputId": "1d3282dc-a6f1-47d5-eef0-bc252c7f3102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "#\n",
        "# 실행하지마...\n",
        "#\n",
        "\n",
        "signals_path = 'signals/npy/Fpz-Cz/remove_wake/'\n",
        "\n",
        "save_train_path = 'signals/npy//Fpz-Cz/remove_wake/train/'\n",
        "save_test_path = 'signals/npy/Fpz-Cz/remove_wake/test/'\n",
        "\n",
        "os.makedirs(save_train_path,exist_ok=True)\n",
        "os.makedirs(save_test_path,exist_ok=True)\n",
        "\n",
        "for filename in annotations_npy_list[:trainDataset_count]:\n",
        "    signals_filename = search_correct_signals_npy(signals_path,filename)[0]\n",
        "    shutil.copy(signals_path+signals_filename,save_train_path+filename)\n",
        "    \n",
        "\n",
        "        \n",
        "for filename in annotations_npy_list[trainDataset_count:]:\n",
        "    signals_filename = search_correct_signals_npy(signals_path,filename)[0]\n",
        "    shutil.copy(signals_path+signals_filename,save_test_path+filename)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-998027a84e68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mannotations_npy_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrainDataset_count\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msignals_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_correct_signals_npy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignals_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignals_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msignals_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_train_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4EYtlUH-e9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f81171c-d811-465f-ae29-ee75ce997fac"
      },
      "source": [
        "def search_correct_annotations_npy(dirname,filename):\n",
        "    search_filename = filename.split('-')[0][:-2]\n",
        "    file_list = os.listdir(dirname)\n",
        "    filename = [file for file in file_list if search_filename in file if file.endswith(\"npy\")]\n",
        "    \n",
        "    return filename\n",
        "\n",
        "train_path =  'signals/npy/Fpz-Cz/remove_wake/train/'\n",
        "test_path = 'signals/npy/Fpz-Cz/remove_wake/test/'\n",
        "annotations_path = 'annotations/npy/remove_wake/'\n",
        "\n",
        "train_list = search_signals_npy(train_path)\n",
        "test_list = search_signals_npy(test_path)\n",
        "\n",
        "print(train_list)\n",
        "print(test_list)\n",
        "\n",
        "train_label = np.zeros([6],dtype=int)\n",
        "test_label = np.zeros([6],dtype=int)\n",
        "\n",
        "for filename in train_list:\n",
        "    filename = search_correct_annotations_npy(annotations_path,filename)[0]\n",
        "    label = np.load(annotations_path + filename)\n",
        "    \n",
        "    for i in range(6):\n",
        "        train_label[i] += np.bincount(label,minlength=6)[i]\n",
        "\n",
        "        \n",
        "for filename in test_list:\n",
        "    filename = search_correct_annotations_npy(annotations_path,filename)[0]\n",
        "    label = np.load(annotations_path + filename)\n",
        "    \n",
        "    for i in range(6):\n",
        "        test_label[i] += np.bincount(label,minlength=6)[i]\n",
        "        \n",
        "train_label = train_label / np.sum(train_label) * 100\n",
        "test_label = test_label / np.sum(test_label) * 100\n",
        "print(train_label)\n",
        "print(test_label)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SC4182EC-Hypnogram.npy', 'SC4141EU-Hypnogram.npy', 'SC4062EC-Hypnogram.npy', 'SC4112EC-Hypnogram.npy', 'SC4151EC-Hypnogram.npy', 'SC4002EC-Hypnogram.npy', 'SC4122EV-Hypnogram.npy', 'SC4081EC-Hypnogram.npy', 'SC4042EC-Hypnogram.npy', 'SC4012EC-Hypnogram.npy', 'SC4181EC-Hypnogram.npy', 'SC4172EC-Hypnogram.npy', 'SC4162EC-Hypnogram.npy', 'SC4061EC-Hypnogram.npy', 'SC4031EC-Hypnogram.npy', 'SC4101EC-Hypnogram.npy', 'SC4111EC-Hypnogram.npy', 'SC4022EJ-Hypnogram.npy', 'SC4171EU-Hypnogram.npy', 'SC4161EC-Hypnogram.npy', 'SC4152EC-Hypnogram.npy', 'SC4052EC-Hypnogram.npy', 'SC4191EP-Hypnogram.npy', 'SC4001EC-Hypnogram.npy', 'SC4071EC-Hypnogram.npy', 'SC4121EC-Hypnogram.npy', 'SC4102EC-Hypnogram.npy', 'SC4041EC-Hypnogram.npy', 'SC4032EP-Hypnogram.npy', 'SC4051EC-Hypnogram.npy']\n",
            "['SC4192EV-Hypnogram.npy', 'SC4092EC-Hypnogram.npy', 'SC4072EH-Hypnogram.npy', 'SC4142EU-Hypnogram.npy', 'SC4091EC-Hypnogram.npy', 'SC4082EP-Hypnogram.npy', 'SC4131EC-Hypnogram.npy', 'SC4011EH-Hypnogram.npy', 'SC4021EH-Hypnogram.npy']\n",
            "[11.63630172  7.56683126 46.24893581 14.88166184 19.55389069  0.11237868]\n",
            "[10.1490889   6.42738818 46.5819989  14.72114854 21.81115406  0.30922142]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QEe0g_XTy9U",
        "outputId": "819a1d83-3f47-47ae-e762-85192218ebdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(train_list))\n",
        "print(len(test_list))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBwqVERu_aw-"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pylab as plt\n",
        "from  torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import warnings\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSQaEXQr_h8m"
      },
      "source": [
        "def data_preprocessing_torch(signals): # 하나의 데이터셋에 대한 data_preprocessing (using torch)\n",
        "    signals = (signals - signals.mean(dim=1).unsqueeze(1))/signals.std(dim=1).unsqueeze(1)\n",
        "\n",
        "    return signals\n",
        "\n",
        "def data_preprocessing_oneToOne_torch(signals,min,max,max_value):\n",
        "    signals_std = (signals + max_value) / (2*max_value)\n",
        "    signals_scaled = signals_std * (max - min) + min\n",
        "    return signals_scaled\n",
        "\n",
        "def data_preprocessing_minmax_torch(signals,min,max):\n",
        "    signals_std = (signals - signals.min(dim=1).unsqueeze(1)) / (\n",
        "            signals.max(dim=1).unsqueeze(1) - signals.min(dim=1).unsqueeze(1))\n",
        "    signals_scaled = signals_std * (max - min) + min\n",
        "    return signals_scaled\n",
        "\n",
        "def get_dataset_one_channel_norm_withoutCut(dirname,annotations_dir,data_path,use_noise=True,epsilon=0.5,noise_scale=2e-6,preprocessing=True,norm_methods='Standard'):\n",
        "    # npy read!\n",
        "    path = dirname + data_path\n",
        "    signals = np.load(path)\n",
        "\n",
        "    signals = torch.from_numpy(signals).float().to(device)\n",
        "\n",
        "    if use_noise:\n",
        "        if np.random.rand() < epsilon:\n",
        "            # noise = np.random.normal(loc=0,scale=noise_scale,size=signals.shape)\n",
        "            # signals = signals + noise\n",
        "            noise = torch.normal(mean=0., std=noise_scale, size=signals.shape).to(device)\n",
        "            signals = signals + noise\n",
        "\n",
        "    if preprocessing:\n",
        "        if norm_methods == 'Standard':\n",
        "            signals = data_preprocessing_torch(signals)\n",
        "        elif norm_methods == 'minmax':\n",
        "            signals = data_preprocessing_minmax_torch(signals,0,1)\n",
        "        elif norm_methods == 'oneToOne':\n",
        "            signals = data_preprocessing_oneToOne_torch(signals,-1,1,1e-4)\n",
        "    label = get_annotations(annotations_dir, data_path)\n",
        "    return signals, label\n",
        "\n",
        "# model conv layer weight init function\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:         # Conv weight init\n",
        "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "        \n",
        "def suffle_dataset_list(dataset_list): # 데이터 셔플\n",
        "    random.shuffle(dataset_list)\n",
        "    return dataset_list\n",
        "\n",
        "\n",
        "# npy파일을 통해 label을 가져오는 함수\n",
        "def get_annotations(label_dir,file_name):\n",
        "    label_path = label_dir + file_name\n",
        "    label = np.load(label_path)\n",
        "    return label\n",
        "\n",
        "def signals_expand_torch_one_channel(signals): # 2차원 데이터를 3차원으로 변환 (8,N) -> (batch,8,6000) 형태로\n",
        "    signals = signals.expand(1,1,-1)\n",
        "    #print(signals.shape)\n",
        "    signals = signals.transpose(2, 1) # 차원 변경\n",
        "    signals = signals.reshape(-1, 3000, 1) # 형태 변환\n",
        "    signals = signals.transpose(2, 1) # 차원 변경\n",
        "    return signals"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx4M7Rfq_lwo"
      },
      "source": [
        "class DeepSleepNet_Classification(nn.Module):  # input channel = 8channel / output = 5\n",
        "    def __init__(self,in_channel=1,out_channel=6,layer=[64,128,128,128],sample_rate = 100):\n",
        "        super(DeepSleepNet_Classification, self).__init__()\n",
        "\n",
        "        self.conv1d_1 = nn.Conv1d(1,16, kernel_size=300, stride=20, padding=280)\n",
        "        self.conv1d_2 = nn.Conv1d(16, 32, kernel_size=20, stride=2, padding=10)\n",
        "        self.conv1d_3 = nn.Conv1d(32, 32, kernel_size=20, stride=2, padding=10)\n",
        "        self.fc1 = nn.Linear(32*42,600)\n",
        "        self.fc2 = nn.Linear(600,300)\n",
        "        self.fc3 = nn.Linear(300,100)        \n",
        "        self.fc4 = nn.Linear(100,out_channel) \n",
        "\n",
        "        self.ReLU = nn.ReLU()\n",
        "        self.LeakyReLU = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.conv1d_1(input)\n",
        "        out = self.LeakyReLU(out)\n",
        "        out = self.conv1d_2(out)\n",
        "        out = self.LeakyReLU(out)\n",
        "        out = self.conv1d_3(out)\n",
        "        out = self.LeakyReLU(out)        \n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.LeakyReLU(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.LeakyReLU(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.LeakyReLU(out)\n",
        "        out = self.dropout(out)        \n",
        "        out = self.fc4(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYZ6YSZHArdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967c6b2f-fbd5-4291-c57b-fc7679eb71ec"
      },
      "source": [
        "model = DeepSleepNet_Classification(in_channel=1,out_channel=6)\n",
        "summary(model.cuda(),(1,3000))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv1d-1              [-1, 16, 164]           4,816\n",
            "         LeakyReLU-2              [-1, 16, 164]               0\n",
            "            Conv1d-3               [-1, 32, 83]          10,272\n",
            "         LeakyReLU-4               [-1, 32, 83]               0\n",
            "            Conv1d-5               [-1, 32, 42]          20,512\n",
            "         LeakyReLU-6               [-1, 32, 42]               0\n",
            "            Linear-7                  [-1, 600]         807,000\n",
            "         LeakyReLU-8                  [-1, 600]               0\n",
            "            Linear-9                  [-1, 300]         180,300\n",
            "        LeakyReLU-10                  [-1, 300]               0\n",
            "          Dropout-11                  [-1, 300]               0\n",
            "           Linear-12                  [-1, 100]          30,100\n",
            "        LeakyReLU-13                  [-1, 100]               0\n",
            "          Dropout-14                  [-1, 100]               0\n",
            "           Linear-15                    [-1, 6]             606\n",
            "================================================================\n",
            "Total params: 1,053,606\n",
            "Trainable params: 1,053,606\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.12\n",
            "Params size (MB): 4.02\n",
            "Estimated Total Size (MB): 4.15\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li3ftAC1Az0Q"
      },
      "source": [
        "def search_npy_list(dirname):  # 매개변수 dir에서 모든 npy파일을 찾고 fold에 따른 dataset 나누기\n",
        "    filenames = os.listdir(dirname)\n",
        "    filenames = [file for _, file in enumerate(filenames) if file.endswith(\".npy\")]\n",
        "    return filenames\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQH_VRRFBGF1"
      },
      "source": [
        "def train_model_withNoise_norm(save_filename,logging_filename,train_signal_dir, test_signal_dir,annotations_dir\n",
        "                               ,epochs=2000,learning_rate=0.001,step_size=100,gamma=0.5,channel=0,\n",
        "                               layer_filters=[64,128,256,512],first_conv=[200,40,100],optim='Adam',lf='CE',\n",
        "                               epsilon=0.7,noise_scale=2e-6,min_value=-1e-4,max_value=1e-4,preprocessing=True,\n",
        "                               norm_methods='Standard',use_noise=True,loss_type='softmax'):\n",
        "    # Adam optimizer param\n",
        "    b1 = 0.5\n",
        "    b2 = 0.999\n",
        "\n",
        "    beta = 0.001\n",
        "\n",
        "    check_file = open(logging_filename, 'w')  # logging file\n",
        "\n",
        "    print('Preproceesing  : ',preprocessing)\n",
        "    print('min/max value : %f/%f'%(min_value,max_value))\n",
        "    print('noise scale : ',noise_scale)\n",
        "    print('loss function : ',lf)\n",
        "    print('epsilon : ',epsilon)\n",
        "    print('norm methods : ',norm_methods)\n",
        "\n",
        "    print('logging file name : ', logging_filename)\n",
        "    print('save file name : ', save_filename)\n",
        "    print('layer filters : ',layer_filters)\n",
        "    print('fisrt_conv info : ',first_conv)\n",
        "    print('loss type : ',loss_type)\n",
        "    print('training data oversampling noise : ',use_noise)\n",
        "    best_accuracy = 0.\n",
        "    best_epoch = 0\n",
        "\n",
        "    train_dataset_list = search_npy_list(train_signal_dir)\n",
        "    test_dataset_list = search_npy_list(test_signal_dir)\n",
        "\n",
        "    train_dataset_len = len(train_dataset_list)\n",
        "    test_dataset_len = len(test_dataset_list)\n",
        "\n",
        "    print('train_dataset length : ', len(train_dataset_list))\n",
        "    print(train_dataset_list)\n",
        "\n",
        "    print('test_dataset length : ',test_dataset_len)\n",
        "    print(test_dataset_list)\n",
        "\n",
        "\n",
        "    model = DeepSleepNet_Classification()\n",
        "\n",
        "    #model = resnet18_200hz(in_channel=1,layer_filters=layer_filters,first_conv=first_conv,use_batchnorm=True,num_classes=5)\n",
        "\n",
        "    model.apply(weights_init) # weight init\n",
        "\n",
        "    cuda = torch.cuda.is_available()\n",
        "\n",
        "    if cuda:\n",
        "        print('can use CUDA!!!')\n",
        "        model = model.cuda()\n",
        "    #summary(model,[1,6000])\n",
        "    print('torch.cuda.device_count() : ', torch.cuda.device_count())\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print('Multi GPU Activation !!!')\n",
        "        #model = nn.DataParallel(model)\n",
        "\n",
        "    # loss funcition\n",
        "    if lf == 'CE':\n",
        "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "    elif lf == 'CEW':\n",
        "        samples_per_cls = [27,15,41,5,11]\n",
        "        no_of_classes = 5\n",
        "        effective_num = 1.0 - np.power(beta,samples_per_cls)\n",
        "        #print(effective_num)\n",
        "        weights = (1.0 - beta) / np.array(effective_num)\n",
        "        #print(weights)\n",
        "        weights = weights / np.sum(weights) * no_of_classes\n",
        "        weights = torch.tensor(weights).float()\n",
        "        weights = weights.to(device)\n",
        "        loss_fn = nn.CrossEntropyLoss(weight=weights).to(device)\n",
        "    elif lf == 'FL':\n",
        "        loss_fn = FocalLoss(gamma=2).to(device)\n",
        "    elif lf == 'CBL':\n",
        "        loss_fn = CB_loss(samples_per_cls=[27,15,41,5,11],no_of_classes=5,loss_type=loss_type,beta=0.9999,gamma=2.0)\n",
        "    #loss_fn = FocalLoss(gamma=2).to(device)\n",
        "\n",
        "    # optimizer ADAM (SGD의 경우에는 정상적으로 학습이 진행되지 않았음)\n",
        "    if optim == 'Adam':\n",
        "        print('Optimizer : Adam')\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(b1, b2))\n",
        "    elif optim == 'RMS':\n",
        "        print('Optimizer : RMSprop')\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "    elif optim == 'SGD':\n",
        "        print('Optimizer : SGD')\n",
        "        optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=gamma, patience=10,\n",
        "                                                           min_lr=1e-6)\n",
        "    #stride = 40 일 때, batch_size = 20이면 16GB정도의 메모리 사용\n",
        "    batch_size = 5\n",
        "    norm_square = 2\n",
        "\n",
        "    train_batch_size = math.ceil(train_dataset_len / batch_size)\n",
        "    print('train_batch_size : ',train_batch_size)\n",
        "\n",
        "    test_batch_size = test_dataset_len\n",
        "\n",
        "    best_accuracy = 0.\n",
        "    stop_count = 0\n",
        "    for epoch in range(epochs):\n",
        "        train_dataset = suffle_dataset_list(train_dataset_list) # 매 epoch마다 train_dataset shuffle !\n",
        "        count = 0  # check batch\n",
        "        train_total_loss = 0.0\n",
        "        train_total_count = 0\n",
        "        train_total_data = 0\n",
        "\n",
        "        val_total_loss = 0.0\n",
        "        val_total_count = 0\n",
        "        val_total_data = 0\n",
        "\n",
        "        test_total_loss = 0.0\n",
        "        test_total_count = 0\n",
        "        test_total_data = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "\n",
        "        output_str = 'current_lr : %f\\n'%(optimizer.state_dict()['param_groups'][0]['lr'])\n",
        "        sys.stdout.write(output_str)\n",
        "        check_file.write(output_str)\n",
        "        for index, file_name in enumerate(train_dataset):\n",
        "            #print('index : ',index)\n",
        "            if index % batch_size == 0:\n",
        "                batch_signal, batch_label = get_dataset_one_channel_norm_withoutCut(train_signal_dir,annotations_dir,file_name,\n",
        "                                                                         use_noise=use_noise,epsilon=epsilon,noise_scale=noise_scale,\n",
        "                                                                         preprocessing=preprocessing,norm_methods=norm_methods)\n",
        "            else:\n",
        "                new_signal, new_label = get_dataset_one_channel_norm_withoutCut(train_signal_dir,annotations_dir,file_name,\n",
        "                                                                         use_noise=use_noise,epsilon=epsilon,noise_scale=noise_scale,\n",
        "                                                                         preprocessing=preprocessing,norm_methods=norm_methods)\n",
        "\n",
        "                batch_signal = torch.cat((batch_signal, new_signal),dim=1)\n",
        "                batch_label = np.concatenate((batch_label, new_label))\n",
        "            count += 1\n",
        "            if count == batch_size or index == len(train_dataset) - 1:  # batch 학습 시작!\n",
        "                batch_signal = signals_expand_torch_one_channel(batch_signal)\n",
        "                #batch_signal = signals_expand_torch_one_channel(batch_signal)\n",
        "                # batch_signal = torch.from_numpy(batch_signal).float().to(device)\n",
        "                batch_label = torch.from_numpy(batch_label).long().to(device)\n",
        "                optimizer.zero_grad()\n",
        "                # print(batch_signal.shape)\n",
        "                # print(batch_signal)\n",
        "                pred = model(batch_signal)\n",
        "                norm = 0\n",
        "\n",
        "                for parameter in model.parameters():\n",
        "                    norm += torch.norm(parameter, p=norm_square)\n",
        "\n",
        "                loss = loss_fn(pred, batch_label) + beta * norm\n",
        "                #print('loss : ',loss.item())\n",
        "                # loss = loss_fn(pred, batch_label)\n",
        "                # acc\n",
        "                _, predict = torch.max(pred, 1)\n",
        "                check_count = (predict == batch_label).sum().item()\n",
        "\n",
        "                train_total_loss += loss.item()\n",
        "\n",
        "                train_total_count += check_count\n",
        "                train_total_data += len(batch_signal)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                del (batch_signal)\n",
        "                del (batch_label)\n",
        "                del (loss)\n",
        "                del (pred)\n",
        "                torch.cuda.empty_cache()\n",
        "                count = 0\n",
        "\n",
        "        train_total_loss /= train_batch_size\n",
        "        train_accuracy = train_total_count / train_total_data * 100\n",
        "\n",
        "        output_str = 'train dataset : %d/%d epochs spend time : %.4f sec / total_loss : %.4f correct : %d/%d -> %.4f%%\\n' \\\n",
        "                     % (epoch + 1, epochs, time.time() - start_time, train_total_loss,\n",
        "                        train_total_count, train_total_data, train_accuracy)\n",
        "        sys.stdout.write(output_str)\n",
        "        check_file.write(output_str)\n",
        "\n",
        "    \n",
        "\n",
        "        #check test dataset\n",
        "        start_time = time.time()\n",
        "        for file_name in test_dataset_list:\n",
        "            batch_signal, batch_label = get_dataset_one_channel_norm_withoutCut(test_signal_dir,annotations_dir,file_name,\n",
        "                                                                         use_noise=False,epsilon=epsilon,noise_scale=noise_scale,\n",
        "                                                                         preprocessing=preprocessing,norm_methods=norm_methods)\n",
        "\n",
        "            batch_signal = signals_expand_torch_one_channel(batch_signal)\n",
        "\n",
        "            batch_label = torch.from_numpy(batch_label).long().to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                pred = model(batch_signal)\n",
        "\n",
        "                loss = loss_fn(pred, batch_label)\n",
        "\n",
        "                # acc\n",
        "                _, predict = torch.max(pred, 1)\n",
        "                check_count = (predict == batch_label).sum().item()\n",
        "\n",
        "                test_total_loss += loss.item()\n",
        "                test_total_count += check_count\n",
        "                test_total_data += len(batch_signal)\n",
        "\n",
        "                # 사용하지 않는 변수 제거\n",
        "                del (batch_signal)\n",
        "                del (batch_label)\n",
        "                del (loss)\n",
        "                del (pred)\n",
        "                torch.cuda.empty_cache()\n",
        "        test_total_loss /= test_batch_size\n",
        "        test_accuracy = test_total_count / test_total_data * 100\n",
        "\n",
        "\n",
        "\n",
        "        output_str = 'test dataset : %d/%d epochs spend time : %.4f sec  / total_loss : %.4f correct : %d/%d -> %.4f%%\\n' \\\n",
        "                     % (epoch + 1, epochs, time.time() - start_time, test_total_loss,\n",
        "                        test_total_count, test_total_data, test_accuracy)\n",
        "        sys.stdout.write(output_str)\n",
        "        check_file.write(output_str)\n",
        "\n",
        "        scheduler.step(float(test_total_loss))\n",
        "        #scheduler.step()\n",
        "\n",
        "        if epoch == 0:\n",
        "            best_accuracy = test_accuracy\n",
        "            best_epoch = epoch\n",
        "            save_file = save_filename\n",
        "            #save_file = save_path + 'best_SleepEEGNet_CNN_channel%d.pth'%channel\n",
        "            torch.save(model.state_dict(),save_file)\n",
        "            stop_count = 0\n",
        "        else:\n",
        "            if best_accuracy < test_accuracy:\n",
        "                best_accuracy = test_accuracy\n",
        "                best_epoch = epoch\n",
        "                save_file = save_filename\n",
        "                torch.save(model.state_dict(), save_file)\n",
        "                stop_count = 0\n",
        "            else:\n",
        "                stop_count += 1\n",
        "        if stop_count > 30:\n",
        "            print('Early Stopping')\n",
        "            break\n",
        "\n",
        "        output_str = 'best epoch : %d/%d / val accuracy : %f%%\\n' \\\n",
        "                     % (best_epoch+1, epochs, best_accuracy)\n",
        "        sys.stdout.write(output_str)\n",
        "        print('=' * 30)\n",
        "\n",
        "\n",
        "    output_str = 'best epoch : %d/%d / accuracy : %f%%\\n' \\\n",
        "                 % (best_epoch+1, epochs, best_accuracy)\n",
        "    sys.stdout.write(output_str)\n",
        "    check_file.write(output_str)\n",
        "    print('=' * 30)\n",
        "\n",
        "    check_file.close()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-qN1b_NBMC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8286a7a-cf3d-440f-e6d4-0f9f51c2269c"
      },
      "source": [
        "save_filename = './train.pth'\n",
        "logging_filename = './logging.txt'\n",
        "train_signal_dir = 'signals/npy/Fpz-Cz/remove_wake/train/'\n",
        "test_signal_dir = 'signals/npy/Fpz-Cz/remove_wake/test/'\n",
        "annotations_dir = 'annotations/npy/remove_wake/'\n",
        "train_model_withNoise_norm(save_filename,logging_filename,train_signal_dir, \n",
        "                           test_signal_dir,annotations_dir,\n",
        "                           epochs=2000,learning_rate=0.001,step_size=100,gamma=0.5,channel=0,\n",
        "                           layer_filters=[64,128,256,512],first_conv=[200,40,100],\n",
        "                           optim='Adam',lf='CE',epsilon=0,noise_scale=0,\n",
        "                           min_value=-0,max_value=0,preprocessing=True,\n",
        "                           norm_methods='Standard',use_noise=False,loss_type='softmax')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preproceesing  :  True\n",
            "min/max value : 0.000000/0.000000\n",
            "noise scale :  0\n",
            "loss function :  CE\n",
            "epsilon :  0\n",
            "norm methods :  Standard\n",
            "logging file name :  ./logging.txt\n",
            "save file name :  ./train.pth\n",
            "layer filters :  [64, 128, 256, 512]\n",
            "fisrt_conv info :  [200, 40, 100]\n",
            "loss type :  softmax\n",
            "training data oversampling noise :  False\n",
            "train_dataset length :  30\n",
            "['SC4182EC-Hypnogram.npy', 'SC4141EU-Hypnogram.npy', 'SC4062EC-Hypnogram.npy', 'SC4112EC-Hypnogram.npy', 'SC4151EC-Hypnogram.npy', 'SC4002EC-Hypnogram.npy', 'SC4122EV-Hypnogram.npy', 'SC4081EC-Hypnogram.npy', 'SC4042EC-Hypnogram.npy', 'SC4012EC-Hypnogram.npy', 'SC4181EC-Hypnogram.npy', 'SC4172EC-Hypnogram.npy', 'SC4162EC-Hypnogram.npy', 'SC4061EC-Hypnogram.npy', 'SC4031EC-Hypnogram.npy', 'SC4101EC-Hypnogram.npy', 'SC4111EC-Hypnogram.npy', 'SC4022EJ-Hypnogram.npy', 'SC4171EU-Hypnogram.npy', 'SC4161EC-Hypnogram.npy', 'SC4052EC-Hypnogram.npy', 'SC4191EP-Hypnogram.npy', 'SC4001EC-Hypnogram.npy', 'SC4071EC-Hypnogram.npy', 'SC4121EC-Hypnogram.npy', 'SC4102EC-Hypnogram.npy', 'SC4041EC-Hypnogram.npy', 'SC4032EP-Hypnogram.npy', 'SC4051EC-Hypnogram.npy', 'SC4092EC-Hypnogram.npy']\n",
            "test_dataset length :  9\n",
            "['SC4192EV-Hypnogram.npy', 'SC4092EC-Hypnogram.npy', 'SC4072EH-Hypnogram.npy', 'SC4142EU-Hypnogram.npy', 'SC4091EC-Hypnogram.npy', 'SC4082EP-Hypnogram.npy', 'SC4131EC-Hypnogram.npy', 'SC4011EH-Hypnogram.npy', 'SC4021EH-Hypnogram.npy']\n",
            "can use CUDA!!!\n",
            "torch.cuda.device_count() :  1\n",
            "Optimizer : Adam\n",
            "train_batch_size :  6\n",
            "current_lr : 0.001000\n",
            "train dataset : 1/2000 epochs spend time : 22.5718 sec / total_loss : 1.7995 correct : 11508/28705 -> 40.0906%\n",
            "test dataset : 1/2000 epochs spend time : 7.4013 sec  / total_loss : 1.5658 correct : 4218/9055 -> 46.5820%\n",
            "best epoch : 1/2000 / val accuracy : 46.581999%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 2/2000 epochs spend time : 2.3686 sec / total_loss : 1.5527 correct : 12179/28705 -> 42.4281%\n",
            "test dataset : 2/2000 epochs spend time : 0.3280 sec  / total_loss : 1.4316 correct : 4218/9055 -> 46.5820%\n",
            "best epoch : 1/2000 / val accuracy : 46.581999%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 3/2000 epochs spend time : 2.3500 sec / total_loss : 1.4715 correct : 13389/28705 -> 46.6434%\n",
            "test dataset : 3/2000 epochs spend time : 0.3169 sec  / total_loss : 1.3981 correct : 4218/9055 -> 46.5820%\n",
            "best epoch : 1/2000 / val accuracy : 46.581999%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 4/2000 epochs spend time : 2.3492 sec / total_loss : 1.4499 correct : 13441/28705 -> 46.8246%\n",
            "test dataset : 4/2000 epochs spend time : 0.3130 sec  / total_loss : 1.3745 correct : 4218/9055 -> 46.5820%\n",
            "best epoch : 1/2000 / val accuracy : 46.581999%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 5/2000 epochs spend time : 2.3510 sec / total_loss : 1.4110 correct : 13776/28705 -> 47.9916%\n",
            "test dataset : 5/2000 epochs spend time : 0.3105 sec  / total_loss : 1.2590 correct : 5088/9055 -> 56.1900%\n",
            "best epoch : 5/2000 / val accuracy : 56.189950%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 6/2000 epochs spend time : 2.3650 sec / total_loss : 1.5028 correct : 12668/28705 -> 44.1317%\n",
            "test dataset : 6/2000 epochs spend time : 0.3339 sec  / total_loss : 1.3103 correct : 4218/9055 -> 46.5820%\n",
            "best epoch : 5/2000 / val accuracy : 56.189950%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 7/2000 epochs spend time : 2.3458 sec / total_loss : 1.3305 correct : 13811/28705 -> 48.1136%\n",
            "test dataset : 7/2000 epochs spend time : 0.3345 sec  / total_loss : 1.1213 correct : 5047/9055 -> 55.7372%\n",
            "best epoch : 5/2000 / val accuracy : 56.189950%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 8/2000 epochs spend time : 2.3459 sec / total_loss : 1.4268 correct : 12889/28705 -> 44.9016%\n",
            "test dataset : 8/2000 epochs spend time : 0.3144 sec  / total_loss : 1.3077 correct : 4218/9055 -> 46.5820%\n",
            "best epoch : 5/2000 / val accuracy : 56.189950%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 9/2000 epochs spend time : 2.3468 sec / total_loss : 1.2467 correct : 14892/28705 -> 51.8795%\n",
            "test dataset : 9/2000 epochs spend time : 0.3193 sec  / total_loss : 1.6230 correct : 4119/9055 -> 45.4887%\n",
            "best epoch : 5/2000 / val accuracy : 56.189950%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 10/2000 epochs spend time : 2.3545 sec / total_loss : 1.2532 correct : 15095/28705 -> 52.5867%\n",
            "test dataset : 10/2000 epochs spend time : 0.3200 sec  / total_loss : 1.0303 correct : 5113/9055 -> 56.4660%\n",
            "best epoch : 10/2000 / val accuracy : 56.466041%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 11/2000 epochs spend time : 2.3529 sec / total_loss : 1.2554 correct : 14286/28705 -> 49.7683%\n",
            "test dataset : 11/2000 epochs spend time : 0.3226 sec  / total_loss : 1.1329 correct : 4680/9055 -> 51.6842%\n",
            "best epoch : 10/2000 / val accuracy : 56.466041%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 12/2000 epochs spend time : 2.3733 sec / total_loss : 1.1623 correct : 15763/28705 -> 54.9138%\n",
            "test dataset : 12/2000 epochs spend time : 0.3202 sec  / total_loss : 1.0036 correct : 5213/9055 -> 57.5704%\n",
            "best epoch : 12/2000 / val accuracy : 57.570403%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 13/2000 epochs spend time : 2.3509 sec / total_loss : 1.0540 correct : 17727/28705 -> 61.7558%\n",
            "test dataset : 13/2000 epochs spend time : 0.3283 sec  / total_loss : 0.9186 correct : 6141/9055 -> 67.8189%\n",
            "best epoch : 13/2000 / val accuracy : 67.818885%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 14/2000 epochs spend time : 2.3663 sec / total_loss : 1.1756 correct : 15832/28705 -> 55.1542%\n",
            "test dataset : 14/2000 epochs spend time : 0.3197 sec  / total_loss : 1.0950 correct : 4874/9055 -> 53.8266%\n",
            "best epoch : 13/2000 / val accuracy : 67.818885%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 15/2000 epochs spend time : 2.3390 sec / total_loss : 1.1120 correct : 17162/28705 -> 59.7875%\n",
            "test dataset : 15/2000 epochs spend time : 0.3180 sec  / total_loss : 1.2460 correct : 4586/9055 -> 50.6461%\n",
            "best epoch : 13/2000 / val accuracy : 67.818885%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 16/2000 epochs spend time : 2.3724 sec / total_loss : 1.1982 correct : 15737/28705 -> 54.8232%\n",
            "test dataset : 16/2000 epochs spend time : 0.3273 sec  / total_loss : 1.0182 correct : 5772/9055 -> 63.7438%\n",
            "best epoch : 13/2000 / val accuracy : 67.818885%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 17/2000 epochs spend time : 2.3522 sec / total_loss : 1.0635 correct : 17899/28705 -> 62.3550%\n",
            "test dataset : 17/2000 epochs spend time : 0.3236 sec  / total_loss : 0.9356 correct : 5878/9055 -> 64.9144%\n",
            "best epoch : 13/2000 / val accuracy : 67.818885%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 18/2000 epochs spend time : 2.3887 sec / total_loss : 1.0833 correct : 17697/28705 -> 61.6513%\n",
            "test dataset : 18/2000 epochs spend time : 0.3253 sec  / total_loss : 0.8944 correct : 6024/9055 -> 66.5268%\n",
            "best epoch : 13/2000 / val accuracy : 67.818885%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 19/2000 epochs spend time : 2.3538 sec / total_loss : 1.0151 correct : 18376/28705 -> 64.0167%\n",
            "test dataset : 19/2000 epochs spend time : 0.3275 sec  / total_loss : 0.8764 correct : 6069/9055 -> 67.0237%\n",
            "best epoch : 13/2000 / val accuracy : 67.818885%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 20/2000 epochs spend time : 2.3736 sec / total_loss : 1.0073 correct : 18427/28705 -> 64.1944%\n",
            "test dataset : 20/2000 epochs spend time : 0.3262 sec  / total_loss : 0.8837 correct : 6106/9055 -> 67.4324%\n",
            "best epoch : 13/2000 / val accuracy : 67.818885%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 21/2000 epochs spend time : 2.3593 sec / total_loss : 1.0002 correct : 18404/28705 -> 64.1143%\n",
            "test dataset : 21/2000 epochs spend time : 0.3189 sec  / total_loss : 0.9733 correct : 5584/9055 -> 61.6676%\n",
            "best epoch : 13/2000 / val accuracy : 67.818885%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 22/2000 epochs spend time : 2.3661 sec / total_loss : 1.0018 correct : 18314/28705 -> 63.8007%\n",
            "test dataset : 22/2000 epochs spend time : 0.3323 sec  / total_loss : 0.8556 correct : 6214/9055 -> 68.6251%\n",
            "best epoch : 22/2000 / val accuracy : 68.625069%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 23/2000 epochs spend time : 2.3856 sec / total_loss : 0.9569 correct : 19315/28705 -> 67.2879%\n",
            "test dataset : 23/2000 epochs spend time : 0.3451 sec  / total_loss : 0.9569 correct : 5749/9055 -> 63.4898%\n",
            "best epoch : 22/2000 / val accuracy : 68.625069%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 24/2000 epochs spend time : 2.3661 sec / total_loss : 1.0349 correct : 18375/28705 -> 64.0132%\n",
            "test dataset : 24/2000 epochs spend time : 0.3459 sec  / total_loss : 0.8765 correct : 6032/9055 -> 66.6151%\n",
            "best epoch : 22/2000 / val accuracy : 68.625069%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 25/2000 epochs spend time : 2.3689 sec / total_loss : 1.0451 correct : 18437/28705 -> 64.2292%\n",
            "test dataset : 25/2000 epochs spend time : 0.3325 sec  / total_loss : 1.0165 correct : 5726/9055 -> 63.2358%\n",
            "best epoch : 22/2000 / val accuracy : 68.625069%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 26/2000 epochs spend time : 2.3718 sec / total_loss : 1.0101 correct : 18644/28705 -> 64.9504%\n",
            "test dataset : 26/2000 epochs spend time : 0.3281 sec  / total_loss : 0.8463 correct : 6214/9055 -> 68.6251%\n",
            "best epoch : 22/2000 / val accuracy : 68.625069%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 27/2000 epochs spend time : 2.3815 sec / total_loss : 0.9391 correct : 19159/28705 -> 66.7445%\n",
            "test dataset : 27/2000 epochs spend time : 0.3293 sec  / total_loss : 0.8937 correct : 6122/9055 -> 67.6091%\n",
            "best epoch : 22/2000 / val accuracy : 68.625069%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 28/2000 epochs spend time : 2.3763 sec / total_loss : 0.9270 correct : 19287/28705 -> 67.1904%\n",
            "test dataset : 28/2000 epochs spend time : 0.3310 sec  / total_loss : 0.8362 correct : 6268/9055 -> 69.2214%\n",
            "best epoch : 28/2000 / val accuracy : 69.221425%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 29/2000 epochs spend time : 2.3891 sec / total_loss : 0.9307 correct : 19353/28705 -> 67.4203%\n",
            "test dataset : 29/2000 epochs spend time : 0.3273 sec  / total_loss : 0.8500 correct : 6164/9055 -> 68.0729%\n",
            "best epoch : 28/2000 / val accuracy : 69.221425%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 30/2000 epochs spend time : 2.3799 sec / total_loss : 0.9051 correct : 19722/28705 -> 68.7058%\n",
            "test dataset : 30/2000 epochs spend time : 0.3309 sec  / total_loss : 0.8611 correct : 6104/9055 -> 67.4103%\n",
            "best epoch : 28/2000 / val accuracy : 69.221425%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 31/2000 epochs spend time : 2.3853 sec / total_loss : 0.8967 correct : 19464/28705 -> 67.8070%\n",
            "test dataset : 31/2000 epochs spend time : 0.3302 sec  / total_loss : 0.9451 correct : 5855/9055 -> 64.6604%\n",
            "best epoch : 28/2000 / val accuracy : 69.221425%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 32/2000 epochs spend time : 2.3846 sec / total_loss : 0.9919 correct : 18468/28705 -> 64.3372%\n",
            "test dataset : 32/2000 epochs spend time : 0.3351 sec  / total_loss : 0.9038 correct : 5883/9055 -> 64.9696%\n",
            "best epoch : 28/2000 / val accuracy : 69.221425%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 33/2000 epochs spend time : 2.4000 sec / total_loss : 0.9323 correct : 19309/28705 -> 67.2670%\n",
            "test dataset : 33/2000 epochs spend time : 0.3326 sec  / total_loss : 0.8041 correct : 6360/9055 -> 70.2374%\n",
            "best epoch : 33/2000 / val accuracy : 70.237438%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 34/2000 epochs spend time : 2.3939 sec / total_loss : 0.8862 correct : 19793/28705 -> 68.9531%\n",
            "test dataset : 34/2000 epochs spend time : 0.3294 sec  / total_loss : 0.8119 correct : 6340/9055 -> 70.0166%\n",
            "best epoch : 33/2000 / val accuracy : 70.237438%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 35/2000 epochs spend time : 2.3785 sec / total_loss : 0.8800 correct : 19793/28705 -> 68.9531%\n",
            "test dataset : 35/2000 epochs spend time : 0.3494 sec  / total_loss : 0.7948 correct : 6369/9055 -> 70.3368%\n",
            "best epoch : 35/2000 / val accuracy : 70.336830%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 36/2000 epochs spend time : 2.3943 sec / total_loss : 0.8508 correct : 20199/28705 -> 70.3675%\n",
            "test dataset : 36/2000 epochs spend time : 0.3438 sec  / total_loss : 0.8546 correct : 6207/9055 -> 68.5478%\n",
            "best epoch : 35/2000 / val accuracy : 70.336830%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 37/2000 epochs spend time : 2.3774 sec / total_loss : 0.8982 correct : 19550/28705 -> 68.1066%\n",
            "test dataset : 37/2000 epochs spend time : 0.3306 sec  / total_loss : 0.8695 correct : 6132/9055 -> 67.7195%\n",
            "best epoch : 35/2000 / val accuracy : 70.336830%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 38/2000 epochs spend time : 2.3623 sec / total_loss : 0.9553 correct : 19227/28705 -> 66.9814%\n",
            "test dataset : 38/2000 epochs spend time : 0.3465 sec  / total_loss : 0.9965 correct : 5644/9055 -> 62.3302%\n",
            "best epoch : 35/2000 / val accuracy : 70.336830%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 39/2000 epochs spend time : 2.3814 sec / total_loss : 0.9820 correct : 18498/28705 -> 64.4417%\n",
            "test dataset : 39/2000 epochs spend time : 0.3267 sec  / total_loss : 0.8964 correct : 6069/9055 -> 67.0237%\n",
            "best epoch : 35/2000 / val accuracy : 70.336830%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 40/2000 epochs spend time : 2.3624 sec / total_loss : 0.8638 correct : 19976/28705 -> 69.5907%\n",
            "test dataset : 40/2000 epochs spend time : 0.3270 sec  / total_loss : 0.7925 correct : 6476/9055 -> 71.5185%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 41/2000 epochs spend time : 2.3963 sec / total_loss : 0.9225 correct : 19323/28705 -> 67.3158%\n",
            "test dataset : 41/2000 epochs spend time : 0.3318 sec  / total_loss : 0.9114 correct : 6039/9055 -> 66.6924%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 42/2000 epochs spend time : 2.3904 sec / total_loss : 0.9331 correct : 19356/28705 -> 67.4308%\n",
            "test dataset : 42/2000 epochs spend time : 0.3245 sec  / total_loss : 0.8167 correct : 6297/9055 -> 69.5417%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 43/2000 epochs spend time : 2.3741 sec / total_loss : 0.8625 correct : 19963/28705 -> 69.5454%\n",
            "test dataset : 43/2000 epochs spend time : 0.3231 sec  / total_loss : 0.7844 correct : 6419/9055 -> 70.8890%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 44/2000 epochs spend time : 2.3775 sec / total_loss : 0.9022 correct : 19526/28705 -> 68.0230%\n",
            "test dataset : 44/2000 epochs spend time : 0.3351 sec  / total_loss : 0.8363 correct : 6232/9055 -> 68.8239%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 45/2000 epochs spend time : 2.3700 sec / total_loss : 0.8748 correct : 19886/28705 -> 69.2771%\n",
            "test dataset : 45/2000 epochs spend time : 0.3254 sec  / total_loss : 0.9049 correct : 5930/9055 -> 65.4887%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 46/2000 epochs spend time : 2.4070 sec / total_loss : 0.8832 correct : 19780/28705 -> 68.9079%\n",
            "test dataset : 46/2000 epochs spend time : 0.3306 sec  / total_loss : 0.7982 correct : 6457/9055 -> 71.3087%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 47/2000 epochs spend time : 2.3868 sec / total_loss : 0.8288 correct : 20383/28705 -> 71.0085%\n",
            "test dataset : 47/2000 epochs spend time : 0.3373 sec  / total_loss : 0.7908 correct : 6417/9055 -> 70.8669%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 48/2000 epochs spend time : 2.3965 sec / total_loss : 0.8312 correct : 20349/28705 -> 70.8901%\n",
            "test dataset : 48/2000 epochs spend time : 0.3374 sec  / total_loss : 0.7993 correct : 6310/9055 -> 69.6853%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 49/2000 epochs spend time : 2.3941 sec / total_loss : 0.8226 correct : 20327/28705 -> 70.8134%\n",
            "test dataset : 49/2000 epochs spend time : 0.3305 sec  / total_loss : 0.8395 correct : 6192/9055 -> 68.3821%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 50/2000 epochs spend time : 2.4045 sec / total_loss : 0.8424 correct : 20318/28705 -> 70.7821%\n",
            "test dataset : 50/2000 epochs spend time : 0.3263 sec  / total_loss : 0.8311 correct : 6284/9055 -> 69.3981%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 51/2000 epochs spend time : 2.3798 sec / total_loss : 0.8647 correct : 20182/28705 -> 70.3083%\n",
            "test dataset : 51/2000 epochs spend time : 0.3438 sec  / total_loss : 0.7771 correct : 6432/9055 -> 71.0326%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 52/2000 epochs spend time : 2.3674 sec / total_loss : 0.8558 correct : 20060/28705 -> 69.8833%\n",
            "test dataset : 52/2000 epochs spend time : 0.3295 sec  / total_loss : 0.8776 correct : 6010/9055 -> 66.3722%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 53/2000 epochs spend time : 2.3826 sec / total_loss : 0.8484 correct : 19869/28705 -> 69.2179%\n",
            "test dataset : 53/2000 epochs spend time : 0.3443 sec  / total_loss : 0.7925 correct : 6379/9055 -> 70.4473%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 54/2000 epochs spend time : 2.3761 sec / total_loss : 0.8267 correct : 20303/28705 -> 70.7298%\n",
            "test dataset : 54/2000 epochs spend time : 0.3362 sec  / total_loss : 0.7847 correct : 6405/9055 -> 70.7344%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 55/2000 epochs spend time : 2.3818 sec / total_loss : 0.8608 correct : 19709/28705 -> 68.6605%\n",
            "test dataset : 55/2000 epochs spend time : 0.3364 sec  / total_loss : 0.7744 correct : 6406/9055 -> 70.7454%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 56/2000 epochs spend time : 2.3783 sec / total_loss : 0.8651 correct : 19874/28705 -> 69.2353%\n",
            "test dataset : 56/2000 epochs spend time : 0.3297 sec  / total_loss : 0.7807 correct : 6410/9055 -> 70.7896%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 57/2000 epochs spend time : 2.3797 sec / total_loss : 0.8175 correct : 20347/28705 -> 70.8831%\n",
            "test dataset : 57/2000 epochs spend time : 0.3314 sec  / total_loss : 0.8272 correct : 6266/9055 -> 69.1993%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 58/2000 epochs spend time : 2.3872 sec / total_loss : 0.8256 correct : 20095/28705 -> 70.0052%\n",
            "test dataset : 58/2000 epochs spend time : 0.3268 sec  / total_loss : 0.8676 correct : 6139/9055 -> 67.7968%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 59/2000 epochs spend time : 2.3979 sec / total_loss : 0.8109 correct : 20281/28705 -> 70.6532%\n",
            "test dataset : 59/2000 epochs spend time : 0.3317 sec  / total_loss : 0.7573 correct : 6434/9055 -> 71.0547%\n",
            "best epoch : 40/2000 / val accuracy : 71.518498%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 60/2000 epochs spend time : 2.4158 sec / total_loss : 0.8730 correct : 20026/28705 -> 69.7648%\n",
            "test dataset : 60/2000 epochs spend time : 0.3654 sec  / total_loss : 0.7715 correct : 6486/9055 -> 71.6289%\n",
            "best epoch : 60/2000 / val accuracy : 71.628934%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 61/2000 epochs spend time : 2.4650 sec / total_loss : 0.9363 correct : 19133/28705 -> 66.6539%\n",
            "test dataset : 61/2000 epochs spend time : 0.3526 sec  / total_loss : 0.7997 correct : 6392/9055 -> 70.5908%\n",
            "best epoch : 60/2000 / val accuracy : 71.628934%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 62/2000 epochs spend time : 2.4575 sec / total_loss : 0.8453 correct : 20327/28705 -> 70.8134%\n",
            "test dataset : 62/2000 epochs spend time : 0.3664 sec  / total_loss : 0.7740 correct : 6419/9055 -> 70.8890%\n",
            "best epoch : 60/2000 / val accuracy : 71.628934%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 63/2000 epochs spend time : 2.4633 sec / total_loss : 0.8121 correct : 20424/28705 -> 71.1514%\n",
            "test dataset : 63/2000 epochs spend time : 0.3437 sec  / total_loss : 0.7570 correct : 6509/9055 -> 71.8829%\n",
            "best epoch : 63/2000 / val accuracy : 71.882938%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 64/2000 epochs spend time : 2.4315 sec / total_loss : 0.8367 correct : 19965/28705 -> 69.5523%\n",
            "test dataset : 64/2000 epochs spend time : 0.3275 sec  / total_loss : 0.7590 correct : 6492/9055 -> 71.6952%\n",
            "best epoch : 63/2000 / val accuracy : 71.882938%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 65/2000 epochs spend time : 2.3780 sec / total_loss : 0.8086 correct : 20411/28705 -> 71.1061%\n",
            "test dataset : 65/2000 epochs spend time : 0.3378 sec  / total_loss : 0.7663 correct : 6453/9055 -> 71.2645%\n",
            "best epoch : 63/2000 / val accuracy : 71.882938%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 66/2000 epochs spend time : 2.3909 sec / total_loss : 0.8101 correct : 20404/28705 -> 71.0817%\n",
            "test dataset : 66/2000 epochs spend time : 0.3362 sec  / total_loss : 0.7401 correct : 6462/9055 -> 71.3639%\n",
            "best epoch : 63/2000 / val accuracy : 71.882938%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 67/2000 epochs spend time : 2.3918 sec / total_loss : 0.8276 correct : 20295/28705 -> 70.7020%\n",
            "test dataset : 67/2000 epochs spend time : 0.3253 sec  / total_loss : 0.7762 correct : 6342/9055 -> 70.0387%\n",
            "best epoch : 63/2000 / val accuracy : 71.882938%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 68/2000 epochs spend time : 2.4133 sec / total_loss : 0.8086 correct : 20424/28705 -> 71.1514%\n",
            "test dataset : 68/2000 epochs spend time : 0.3468 sec  / total_loss : 0.7178 correct : 6545/9055 -> 72.2805%\n",
            "best epoch : 68/2000 / val accuracy : 72.280508%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 69/2000 epochs spend time : 2.3929 sec / total_loss : 0.7979 correct : 20543/28705 -> 71.5659%\n",
            "test dataset : 69/2000 epochs spend time : 0.3299 sec  / total_loss : 0.7694 correct : 6543/9055 -> 72.2584%\n",
            "best epoch : 68/2000 / val accuracy : 72.280508%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 70/2000 epochs spend time : 2.3957 sec / total_loss : 0.7890 correct : 20795/28705 -> 72.4438%\n",
            "test dataset : 70/2000 epochs spend time : 0.3334 sec  / total_loss : 0.7015 correct : 6579/9055 -> 72.6560%\n",
            "best epoch : 70/2000 / val accuracy : 72.655991%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 71/2000 epochs spend time : 2.3748 sec / total_loss : 0.7532 correct : 20949/28705 -> 72.9803%\n",
            "test dataset : 71/2000 epochs spend time : 0.3276 sec  / total_loss : 0.7709 correct : 6445/9055 -> 71.1761%\n",
            "best epoch : 70/2000 / val accuracy : 72.655991%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 72/2000 epochs spend time : 2.3721 sec / total_loss : 0.7877 correct : 20735/28705 -> 72.2348%\n",
            "test dataset : 72/2000 epochs spend time : 0.3270 sec  / total_loss : 0.6662 correct : 6761/9055 -> 74.6659%\n",
            "best epoch : 72/2000 / val accuracy : 74.665930%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 73/2000 epochs spend time : 2.4146 sec / total_loss : 0.7704 correct : 20812/28705 -> 72.5030%\n",
            "test dataset : 73/2000 epochs spend time : 0.3461 sec  / total_loss : 0.7065 correct : 6704/9055 -> 74.0364%\n",
            "best epoch : 72/2000 / val accuracy : 74.665930%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 74/2000 epochs spend time : 2.4041 sec / total_loss : 0.7803 correct : 20610/28705 -> 71.7993%\n",
            "test dataset : 74/2000 epochs spend time : 0.3288 sec  / total_loss : 0.7290 correct : 6670/9055 -> 73.6610%\n",
            "best epoch : 72/2000 / val accuracy : 74.665930%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 75/2000 epochs spend time : 2.3929 sec / total_loss : 0.8239 correct : 20541/28705 -> 71.5590%\n",
            "test dataset : 75/2000 epochs spend time : 0.3358 sec  / total_loss : 0.7684 correct : 6417/9055 -> 70.8669%\n",
            "best epoch : 72/2000 / val accuracy : 74.665930%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 76/2000 epochs spend time : 2.3885 sec / total_loss : 0.7467 correct : 21111/28705 -> 73.5447%\n",
            "test dataset : 76/2000 epochs spend time : 0.3409 sec  / total_loss : 0.6653 correct : 6707/9055 -> 74.0696%\n",
            "best epoch : 72/2000 / val accuracy : 74.665930%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 77/2000 epochs spend time : 2.4057 sec / total_loss : 0.7646 correct : 21185/28705 -> 73.8025%\n",
            "test dataset : 77/2000 epochs spend time : 0.3408 sec  / total_loss : 0.7644 correct : 6352/9055 -> 70.1491%\n",
            "best epoch : 72/2000 / val accuracy : 74.665930%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 78/2000 epochs spend time : 2.4067 sec / total_loss : 0.8254 correct : 20334/28705 -> 70.8378%\n",
            "test dataset : 78/2000 epochs spend time : 0.3354 sec  / total_loss : 0.7608 correct : 6453/9055 -> 71.2645%\n",
            "best epoch : 72/2000 / val accuracy : 74.665930%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 79/2000 epochs spend time : 2.4102 sec / total_loss : 0.8130 correct : 20419/28705 -> 71.1339%\n",
            "test dataset : 79/2000 epochs spend time : 0.3336 sec  / total_loss : 0.7520 correct : 6389/9055 -> 70.5577%\n",
            "best epoch : 72/2000 / val accuracy : 74.665930%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 80/2000 epochs spend time : 2.4102 sec / total_loss : 0.7423 correct : 21006/28705 -> 73.1789%\n",
            "test dataset : 80/2000 epochs spend time : 0.3327 sec  / total_loss : 0.6657 correct : 6706/9055 -> 74.0585%\n",
            "best epoch : 72/2000 / val accuracy : 74.665930%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 81/2000 epochs spend time : 2.3930 sec / total_loss : 0.7439 correct : 21258/28705 -> 74.0568%\n",
            "test dataset : 81/2000 epochs spend time : 0.3377 sec  / total_loss : 0.7413 correct : 6726/9055 -> 74.2794%\n",
            "best epoch : 72/2000 / val accuracy : 74.665930%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 82/2000 epochs spend time : 2.3737 sec / total_loss : 0.7290 correct : 21388/28705 -> 74.5097%\n",
            "test dataset : 82/2000 epochs spend time : 0.3283 sec  / total_loss : 0.6753 correct : 6753/9055 -> 74.5776%\n",
            "best epoch : 72/2000 / val accuracy : 74.665930%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 83/2000 epochs spend time : 2.4273 sec / total_loss : 0.7658 correct : 21020/28705 -> 73.2277%\n",
            "test dataset : 83/2000 epochs spend time : 0.3331 sec  / total_loss : 0.6791 correct : 6936/9055 -> 76.5986%\n",
            "best epoch : 83/2000 / val accuracy : 76.598564%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 84/2000 epochs spend time : 2.4063 sec / total_loss : 0.7634 correct : 21148/28705 -> 73.6736%\n",
            "test dataset : 84/2000 epochs spend time : 0.3450 sec  / total_loss : 0.7207 correct : 6502/9055 -> 71.8056%\n",
            "best epoch : 83/2000 / val accuracy : 76.598564%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 85/2000 epochs spend time : 2.4013 sec / total_loss : 0.7785 correct : 20698/28705 -> 72.1059%\n",
            "test dataset : 85/2000 epochs spend time : 0.3444 sec  / total_loss : 0.8257 correct : 6553/9055 -> 72.3689%\n",
            "best epoch : 83/2000 / val accuracy : 76.598564%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 86/2000 epochs spend time : 2.3926 sec / total_loss : 0.7701 correct : 21092/28705 -> 73.4785%\n",
            "test dataset : 86/2000 epochs spend time : 0.3485 sec  / total_loss : 0.7536 correct : 6364/9055 -> 70.2816%\n",
            "best epoch : 83/2000 / val accuracy : 76.598564%\n",
            "==============================\n",
            "current_lr : 0.001000\n",
            "train dataset : 87/2000 epochs spend time : 2.3873 sec / total_loss : 0.7089 correct : 21629/28705 -> 75.3492%\n",
            "test dataset : 87/2000 epochs spend time : 0.3333 sec  / total_loss : 0.6721 correct : 6668/9055 -> 73.6389%\n",
            "best epoch : 83/2000 / val accuracy : 76.598564%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 88/2000 epochs spend time : 2.3989 sec / total_loss : 0.6755 correct : 21996/28705 -> 76.6278%\n",
            "test dataset : 88/2000 epochs spend time : 0.3410 sec  / total_loss : 0.6264 correct : 6874/9055 -> 75.9139%\n",
            "best epoch : 83/2000 / val accuracy : 76.598564%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 89/2000 epochs spend time : 2.3949 sec / total_loss : 0.6637 correct : 22078/28705 -> 76.9134%\n",
            "test dataset : 89/2000 epochs spend time : 0.3400 sec  / total_loss : 0.6351 correct : 6944/9055 -> 76.6869%\n",
            "best epoch : 89/2000 / val accuracy : 76.686913%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 90/2000 epochs spend time : 2.3990 sec / total_loss : 0.6545 correct : 22215/28705 -> 77.3907%\n",
            "test dataset : 90/2000 epochs spend time : 0.3363 sec  / total_loss : 0.6154 correct : 6950/9055 -> 76.7532%\n",
            "best epoch : 90/2000 / val accuracy : 76.753175%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 91/2000 epochs spend time : 2.4037 sec / total_loss : 0.6565 correct : 22096/28705 -> 76.9761%\n",
            "test dataset : 91/2000 epochs spend time : 0.3364 sec  / total_loss : 0.6391 correct : 6829/9055 -> 75.4169%\n",
            "best epoch : 90/2000 / val accuracy : 76.753175%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 92/2000 epochs spend time : 2.3869 sec / total_loss : 0.6649 correct : 22153/28705 -> 77.1747%\n",
            "test dataset : 92/2000 epochs spend time : 0.3397 sec  / total_loss : 0.6193 correct : 6926/9055 -> 76.4881%\n",
            "best epoch : 90/2000 / val accuracy : 76.753175%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 93/2000 epochs spend time : 2.4250 sec / total_loss : 0.6449 correct : 22279/28705 -> 77.6137%\n",
            "test dataset : 93/2000 epochs spend time : 0.3409 sec  / total_loss : 0.6272 correct : 6864/9055 -> 75.8034%\n",
            "best epoch : 90/2000 / val accuracy : 76.753175%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 94/2000 epochs spend time : 2.4333 sec / total_loss : 0.6595 correct : 22106/28705 -> 77.0110%\n",
            "test dataset : 94/2000 epochs spend time : 0.3322 sec  / total_loss : 0.5922 correct : 7059/9055 -> 77.9569%\n",
            "best epoch : 94/2000 / val accuracy : 77.956930%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 95/2000 epochs spend time : 2.4154 sec / total_loss : 0.6476 correct : 22274/28705 -> 77.5962%\n",
            "test dataset : 95/2000 epochs spend time : 0.3373 sec  / total_loss : 0.5916 correct : 7034/9055 -> 77.6808%\n",
            "best epoch : 94/2000 / val accuracy : 77.956930%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 96/2000 epochs spend time : 2.4128 sec / total_loss : 0.6447 correct : 22248/28705 -> 77.5057%\n",
            "test dataset : 96/2000 epochs spend time : 0.3352 sec  / total_loss : 0.6169 correct : 6994/9055 -> 77.2391%\n",
            "best epoch : 94/2000 / val accuracy : 77.956930%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 97/2000 epochs spend time : 2.4044 sec / total_loss : 0.6611 correct : 21983/28705 -> 76.5825%\n",
            "test dataset : 97/2000 epochs spend time : 0.3349 sec  / total_loss : 0.6082 correct : 6976/9055 -> 77.0403%\n",
            "best epoch : 94/2000 / val accuracy : 77.956930%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 98/2000 epochs spend time : 2.4048 sec / total_loss : 0.6611 correct : 22198/28705 -> 77.3315%\n",
            "test dataset : 98/2000 epochs spend time : 0.3372 sec  / total_loss : 0.6036 correct : 7049/9055 -> 77.8465%\n",
            "best epoch : 94/2000 / val accuracy : 77.956930%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 99/2000 epochs spend time : 2.3901 sec / total_loss : 0.6310 correct : 22438/28705 -> 78.1676%\n",
            "test dataset : 99/2000 epochs spend time : 0.3615 sec  / total_loss : 0.6002 correct : 7029/9055 -> 77.6256%\n",
            "best epoch : 94/2000 / val accuracy : 77.956930%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 100/2000 epochs spend time : 2.4015 sec / total_loss : 0.6505 correct : 22097/28705 -> 76.9796%\n",
            "test dataset : 100/2000 epochs spend time : 0.3310 sec  / total_loss : 0.6023 correct : 7025/9055 -> 77.5814%\n",
            "best epoch : 94/2000 / val accuracy : 77.956930%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 101/2000 epochs spend time : 2.4239 sec / total_loss : 0.6467 correct : 22163/28705 -> 77.2095%\n",
            "test dataset : 101/2000 epochs spend time : 0.3373 sec  / total_loss : 0.5914 correct : 7049/9055 -> 77.8465%\n",
            "best epoch : 94/2000 / val accuracy : 77.956930%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 102/2000 epochs spend time : 2.3998 sec / total_loss : 0.6358 correct : 22411/28705 -> 78.0735%\n",
            "test dataset : 102/2000 epochs spend time : 0.3388 sec  / total_loss : 0.6030 correct : 7023/9055 -> 77.5594%\n",
            "best epoch : 94/2000 / val accuracy : 77.956930%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 103/2000 epochs spend time : 2.3987 sec / total_loss : 0.6456 correct : 22097/28705 -> 76.9796%\n",
            "test dataset : 103/2000 epochs spend time : 0.3360 sec  / total_loss : 0.5847 correct : 7057/9055 -> 77.9348%\n",
            "best epoch : 94/2000 / val accuracy : 77.956930%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 104/2000 epochs spend time : 2.4021 sec / total_loss : 0.6483 correct : 22314/28705 -> 77.7356%\n",
            "test dataset : 104/2000 epochs spend time : 0.3414 sec  / total_loss : 0.5812 correct : 7123/9055 -> 78.6637%\n",
            "best epoch : 104/2000 / val accuracy : 78.663722%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 105/2000 epochs spend time : 2.4019 sec / total_loss : 0.6479 correct : 22108/28705 -> 77.0179%\n",
            "test dataset : 105/2000 epochs spend time : 0.3393 sec  / total_loss : 0.6045 correct : 7012/9055 -> 77.4379%\n",
            "best epoch : 104/2000 / val accuracy : 78.663722%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 106/2000 epochs spend time : 2.4143 sec / total_loss : 0.6324 correct : 22416/28705 -> 78.0909%\n",
            "test dataset : 106/2000 epochs spend time : 0.3541 sec  / total_loss : 0.5816 correct : 7115/9055 -> 78.5754%\n",
            "best epoch : 104/2000 / val accuracy : 78.663722%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 107/2000 epochs spend time : 2.4363 sec / total_loss : 0.6146 correct : 22539/28705 -> 78.5194%\n",
            "test dataset : 107/2000 epochs spend time : 0.3500 sec  / total_loss : 0.5749 correct : 7121/9055 -> 78.6416%\n",
            "best epoch : 104/2000 / val accuracy : 78.663722%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 108/2000 epochs spend time : 2.4209 sec / total_loss : 0.6170 correct : 22491/28705 -> 78.3522%\n",
            "test dataset : 108/2000 epochs spend time : 0.3347 sec  / total_loss : 0.6176 correct : 6988/9055 -> 77.1728%\n",
            "best epoch : 104/2000 / val accuracy : 78.663722%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 109/2000 epochs spend time : 2.4041 sec / total_loss : 0.6496 correct : 22150/28705 -> 77.1643%\n",
            "test dataset : 109/2000 epochs spend time : 0.3385 sec  / total_loss : 0.6020 correct : 7007/9055 -> 77.3827%\n",
            "best epoch : 104/2000 / val accuracy : 78.663722%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 110/2000 epochs spend time : 2.4094 sec / total_loss : 0.6261 correct : 22460/28705 -> 78.2442%\n",
            "test dataset : 110/2000 epochs spend time : 0.3389 sec  / total_loss : 0.5802 correct : 7071/9055 -> 78.0895%\n",
            "best epoch : 104/2000 / val accuracy : 78.663722%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 111/2000 epochs spend time : 2.4272 sec / total_loss : 0.6113 correct : 22575/28705 -> 78.6448%\n",
            "test dataset : 111/2000 epochs spend time : 0.3454 sec  / total_loss : 0.5835 correct : 7072/9055 -> 78.1005%\n",
            "best epoch : 104/2000 / val accuracy : 78.663722%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 112/2000 epochs spend time : 2.4185 sec / total_loss : 0.6316 correct : 22322/28705 -> 77.7635%\n",
            "test dataset : 112/2000 epochs spend time : 0.3487 sec  / total_loss : 0.5741 correct : 7099/9055 -> 78.3987%\n",
            "best epoch : 104/2000 / val accuracy : 78.663722%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 113/2000 epochs spend time : 2.4059 sec / total_loss : 0.6154 correct : 22576/28705 -> 78.6483%\n",
            "test dataset : 113/2000 epochs spend time : 0.3528 sec  / total_loss : 0.5987 correct : 7043/9055 -> 77.7802%\n",
            "best epoch : 104/2000 / val accuracy : 78.663722%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 114/2000 epochs spend time : 2.3958 sec / total_loss : 0.6358 correct : 22204/28705 -> 77.3524%\n",
            "test dataset : 114/2000 epochs spend time : 0.3369 sec  / total_loss : 0.5864 correct : 7068/9055 -> 78.0563%\n",
            "best epoch : 104/2000 / val accuracy : 78.663722%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 115/2000 epochs spend time : 2.4133 sec / total_loss : 0.6044 correct : 22652/28705 -> 78.9131%\n",
            "test dataset : 115/2000 epochs spend time : 0.3373 sec  / total_loss : 0.5665 correct : 7130/9055 -> 78.7410%\n",
            "best epoch : 115/2000 / val accuracy : 78.741027%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 116/2000 epochs spend time : 2.4187 sec / total_loss : 0.6225 correct : 22528/28705 -> 78.4811%\n",
            "test dataset : 116/2000 epochs spend time : 0.3408 sec  / total_loss : 0.5762 correct : 7101/9055 -> 78.4208%\n",
            "best epoch : 115/2000 / val accuracy : 78.741027%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 117/2000 epochs spend time : 2.3967 sec / total_loss : 0.5969 correct : 22727/28705 -> 79.1744%\n",
            "test dataset : 117/2000 epochs spend time : 0.3443 sec  / total_loss : 0.5796 correct : 7111/9055 -> 78.5312%\n",
            "best epoch : 115/2000 / val accuracy : 78.741027%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 118/2000 epochs spend time : 2.4246 sec / total_loss : 0.6002 correct : 22657/28705 -> 78.9305%\n",
            "test dataset : 118/2000 epochs spend time : 0.3331 sec  / total_loss : 0.5801 correct : 7107/9055 -> 78.4870%\n",
            "best epoch : 115/2000 / val accuracy : 78.741027%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 119/2000 epochs spend time : 2.4303 sec / total_loss : 0.5963 correct : 22687/28705 -> 79.0350%\n",
            "test dataset : 119/2000 epochs spend time : 0.3417 sec  / total_loss : 0.5805 correct : 7098/9055 -> 78.3876%\n",
            "best epoch : 115/2000 / val accuracy : 78.741027%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 120/2000 epochs spend time : 2.4072 sec / total_loss : 0.6218 correct : 22449/28705 -> 78.2059%\n",
            "test dataset : 120/2000 epochs spend time : 0.3441 sec  / total_loss : 0.7802 correct : 6611/9055 -> 73.0094%\n",
            "best epoch : 115/2000 / val accuracy : 78.741027%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 121/2000 epochs spend time : 2.4051 sec / total_loss : 0.6974 correct : 21857/28705 -> 76.1435%\n",
            "test dataset : 121/2000 epochs spend time : 0.3481 sec  / total_loss : 0.5828 correct : 7071/9055 -> 78.0895%\n",
            "best epoch : 115/2000 / val accuracy : 78.741027%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 122/2000 epochs spend time : 2.4027 sec / total_loss : 0.6017 correct : 22682/28705 -> 79.0176%\n",
            "test dataset : 122/2000 epochs spend time : 0.3363 sec  / total_loss : 0.5810 correct : 7105/9055 -> 78.4649%\n",
            "best epoch : 115/2000 / val accuracy : 78.741027%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 123/2000 epochs spend time : 2.4079 sec / total_loss : 0.6030 correct : 22704/28705 -> 79.0942%\n",
            "test dataset : 123/2000 epochs spend time : 0.3322 sec  / total_loss : 0.5918 correct : 7089/9055 -> 78.2882%\n",
            "best epoch : 115/2000 / val accuracy : 78.741027%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 124/2000 epochs spend time : 2.4162 sec / total_loss : 0.6014 correct : 22678/28705 -> 79.0037%\n",
            "test dataset : 124/2000 epochs spend time : 0.3418 sec  / total_loss : 0.5941 correct : 7106/9055 -> 78.4760%\n",
            "best epoch : 115/2000 / val accuracy : 78.741027%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 125/2000 epochs spend time : 2.4122 sec / total_loss : 0.6035 correct : 22601/28705 -> 78.7354%\n",
            "test dataset : 125/2000 epochs spend time : 0.3663 sec  / total_loss : 0.5722 correct : 7103/9055 -> 78.4428%\n",
            "best epoch : 115/2000 / val accuracy : 78.741027%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 126/2000 epochs spend time : 2.4215 sec / total_loss : 0.5925 correct : 22717/28705 -> 79.1395%\n",
            "test dataset : 126/2000 epochs spend time : 0.3426 sec  / total_loss : 0.5573 correct : 7166/9055 -> 79.1386%\n",
            "best epoch : 126/2000 / val accuracy : 79.138597%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 127/2000 epochs spend time : 2.4332 sec / total_loss : 0.5812 correct : 22891/28705 -> 79.7457%\n",
            "test dataset : 127/2000 epochs spend time : 0.3427 sec  / total_loss : 0.5672 correct : 7131/9055 -> 78.7521%\n",
            "best epoch : 126/2000 / val accuracy : 79.138597%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 128/2000 epochs spend time : 2.4120 sec / total_loss : 0.5787 correct : 22932/28705 -> 79.8885%\n",
            "test dataset : 128/2000 epochs spend time : 0.3490 sec  / total_loss : 0.5656 correct : 7117/9055 -> 78.5975%\n",
            "best epoch : 126/2000 / val accuracy : 79.138597%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 129/2000 epochs spend time : 2.4361 sec / total_loss : 0.5891 correct : 22736/28705 -> 79.2057%\n",
            "test dataset : 129/2000 epochs spend time : 0.3451 sec  / total_loss : 0.5900 correct : 7068/9055 -> 78.0563%\n",
            "best epoch : 126/2000 / val accuracy : 79.138597%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 130/2000 epochs spend time : 2.4135 sec / total_loss : 0.6026 correct : 22672/28705 -> 78.9828%\n",
            "test dataset : 130/2000 epochs spend time : 0.3303 sec  / total_loss : 0.6163 correct : 7061/9055 -> 77.9790%\n",
            "best epoch : 126/2000 / val accuracy : 79.138597%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 131/2000 epochs spend time : 2.4009 sec / total_loss : 0.6243 correct : 22377/28705 -> 77.9551%\n",
            "test dataset : 131/2000 epochs spend time : 0.3485 sec  / total_loss : 0.5605 correct : 7151/9055 -> 78.9729%\n",
            "best epoch : 126/2000 / val accuracy : 79.138597%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 132/2000 epochs spend time : 2.4163 sec / total_loss : 0.5876 correct : 22819/28705 -> 79.4949%\n",
            "test dataset : 132/2000 epochs spend time : 0.3558 sec  / total_loss : 0.5676 correct : 7105/9055 -> 78.4649%\n",
            "best epoch : 126/2000 / val accuracy : 79.138597%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 133/2000 epochs spend time : 2.4138 sec / total_loss : 0.5908 correct : 22713/28705 -> 79.1256%\n",
            "test dataset : 133/2000 epochs spend time : 0.3433 sec  / total_loss : 0.5954 correct : 7046/9055 -> 77.8134%\n",
            "best epoch : 126/2000 / val accuracy : 79.138597%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 134/2000 epochs spend time : 2.4108 sec / total_loss : 0.6358 correct : 22247/28705 -> 77.5022%\n",
            "test dataset : 134/2000 epochs spend time : 0.3423 sec  / total_loss : 0.5818 correct : 7038/9055 -> 77.7250%\n",
            "best epoch : 126/2000 / val accuracy : 79.138597%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 135/2000 epochs spend time : 2.4156 sec / total_loss : 0.5796 correct : 23024/28705 -> 80.2090%\n",
            "test dataset : 135/2000 epochs spend time : 0.3520 sec  / total_loss : 0.5675 correct : 7171/9055 -> 79.1938%\n",
            "best epoch : 135/2000 / val accuracy : 79.193816%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 136/2000 epochs spend time : 2.4385 sec / total_loss : 0.5984 correct : 22709/28705 -> 79.1117%\n",
            "test dataset : 136/2000 epochs spend time : 0.3583 sec  / total_loss : 0.5911 correct : 7110/9055 -> 78.5202%\n",
            "best epoch : 135/2000 / val accuracy : 79.193816%\n",
            "==============================\n",
            "current_lr : 0.000500\n",
            "train dataset : 137/2000 epochs spend time : 2.4239 sec / total_loss : 0.6265 correct : 22425/28705 -> 78.1223%\n",
            "test dataset : 137/2000 epochs spend time : 0.3419 sec  / total_loss : 0.6801 correct : 6810/9055 -> 75.2071%\n",
            "best epoch : 135/2000 / val accuracy : 79.193816%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 138/2000 epochs spend time : 2.4424 sec / total_loss : 0.6407 correct : 22255/28705 -> 77.5300%\n",
            "test dataset : 138/2000 epochs spend time : 0.3484 sec  / total_loss : 0.5772 correct : 7107/9055 -> 78.4870%\n",
            "best epoch : 135/2000 / val accuracy : 79.193816%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 139/2000 epochs spend time : 2.4197 sec / total_loss : 0.5709 correct : 22997/28705 -> 80.1150%\n",
            "test dataset : 139/2000 epochs spend time : 0.3448 sec  / total_loss : 0.5671 correct : 7163/9055 -> 79.1055%\n",
            "best epoch : 135/2000 / val accuracy : 79.193816%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 140/2000 epochs spend time : 2.4469 sec / total_loss : 0.5648 correct : 23055/28705 -> 80.3170%\n",
            "test dataset : 140/2000 epochs spend time : 0.3373 sec  / total_loss : 0.5653 correct : 7165/9055 -> 79.1276%\n",
            "best epoch : 135/2000 / val accuracy : 79.193816%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 141/2000 epochs spend time : 2.4146 sec / total_loss : 0.5661 correct : 23063/28705 -> 80.3449%\n",
            "test dataset : 141/2000 epochs spend time : 0.3368 sec  / total_loss : 0.5603 correct : 7195/9055 -> 79.4589%\n",
            "best epoch : 141/2000 / val accuracy : 79.458863%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 142/2000 epochs spend time : 2.4139 sec / total_loss : 0.5607 correct : 23078/28705 -> 80.3971%\n",
            "test dataset : 142/2000 epochs spend time : 0.3437 sec  / total_loss : 0.5586 correct : 7186/9055 -> 79.3595%\n",
            "best epoch : 141/2000 / val accuracy : 79.458863%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 143/2000 epochs spend time : 2.4181 sec / total_loss : 0.5621 correct : 23047/28705 -> 80.2891%\n",
            "test dataset : 143/2000 epochs spend time : 0.3459 sec  / total_loss : 0.5616 correct : 7204/9055 -> 79.5583%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 144/2000 epochs spend time : 2.4279 sec / total_loss : 0.5564 correct : 23094/28705 -> 80.4529%\n",
            "test dataset : 144/2000 epochs spend time : 0.3451 sec  / total_loss : 0.5619 correct : 7163/9055 -> 79.1055%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 145/2000 epochs spend time : 2.4227 sec / total_loss : 0.5492 correct : 23172/28705 -> 80.7246%\n",
            "test dataset : 145/2000 epochs spend time : 0.3386 sec  / total_loss : 0.5582 correct : 7180/9055 -> 79.2932%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 146/2000 epochs spend time : 2.4053 sec / total_loss : 0.5575 correct : 23162/28705 -> 80.6898%\n",
            "test dataset : 146/2000 epochs spend time : 0.3652 sec  / total_loss : 0.5576 correct : 7181/9055 -> 79.3043%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 147/2000 epochs spend time : 2.4289 sec / total_loss : 0.5519 correct : 23251/28705 -> 80.9998%\n",
            "test dataset : 147/2000 epochs spend time : 0.3553 sec  / total_loss : 0.5560 correct : 7204/9055 -> 79.5583%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 148/2000 epochs spend time : 2.4211 sec / total_loss : 0.5461 correct : 23236/28705 -> 80.9476%\n",
            "test dataset : 148/2000 epochs spend time : 0.3375 sec  / total_loss : 0.5569 correct : 7204/9055 -> 79.5583%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 149/2000 epochs spend time : 2.4239 sec / total_loss : 0.5453 correct : 23241/28705 -> 80.9650%\n",
            "test dataset : 149/2000 epochs spend time : 0.3387 sec  / total_loss : 0.5566 correct : 7152/9055 -> 78.9840%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 150/2000 epochs spend time : 2.4399 sec / total_loss : 0.5544 correct : 23193/28705 -> 80.7978%\n",
            "test dataset : 150/2000 epochs spend time : 0.3488 sec  / total_loss : 0.5610 correct : 7171/9055 -> 79.1938%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 151/2000 epochs spend time : 2.4334 sec / total_loss : 0.5430 correct : 23211/28705 -> 80.8605%\n",
            "test dataset : 151/2000 epochs spend time : 0.3471 sec  / total_loss : 0.5551 correct : 7183/9055 -> 79.3263%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 152/2000 epochs spend time : 2.4281 sec / total_loss : 0.5352 correct : 23356/28705 -> 81.3656%\n",
            "test dataset : 152/2000 epochs spend time : 0.3359 sec  / total_loss : 0.5650 correct : 7127/9055 -> 78.7079%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 153/2000 epochs spend time : 2.4117 sec / total_loss : 0.5425 correct : 23272/28705 -> 81.0730%\n",
            "test dataset : 153/2000 epochs spend time : 0.3332 sec  / total_loss : 0.5590 correct : 7162/9055 -> 79.0944%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 154/2000 epochs spend time : 2.4076 sec / total_loss : 0.5421 correct : 23339/28705 -> 81.3064%\n",
            "test dataset : 154/2000 epochs spend time : 0.3392 sec  / total_loss : 0.5580 correct : 7187/9055 -> 79.3705%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 155/2000 epochs spend time : 2.4261 sec / total_loss : 0.5403 correct : 23238/28705 -> 80.9545%\n",
            "test dataset : 155/2000 epochs spend time : 0.3431 sec  / total_loss : 0.5549 correct : 7188/9055 -> 79.3816%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 156/2000 epochs spend time : 2.4141 sec / total_loss : 0.5302 correct : 23431/28705 -> 81.6269%\n",
            "test dataset : 156/2000 epochs spend time : 0.3366 sec  / total_loss : 0.5583 correct : 7204/9055 -> 79.5583%\n",
            "best epoch : 143/2000 / val accuracy : 79.558255%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 157/2000 epochs spend time : 2.4016 sec / total_loss : 0.5360 correct : 23371/28705 -> 81.4179%\n",
            "test dataset : 157/2000 epochs spend time : 0.3376 sec  / total_loss : 0.5530 correct : 7209/9055 -> 79.6135%\n",
            "best epoch : 157/2000 / val accuracy : 79.613473%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 158/2000 epochs spend time : 2.4031 sec / total_loss : 0.5336 correct : 23391/28705 -> 81.4875%\n",
            "test dataset : 158/2000 epochs spend time : 0.3572 sec  / total_loss : 0.5618 correct : 7192/9055 -> 79.4257%\n",
            "best epoch : 157/2000 / val accuracy : 79.613473%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 159/2000 epochs spend time : 2.3898 sec / total_loss : 0.5368 correct : 23345/28705 -> 81.3273%\n",
            "test dataset : 159/2000 epochs spend time : 0.3477 sec  / total_loss : 0.5575 correct : 7199/9055 -> 79.5030%\n",
            "best epoch : 157/2000 / val accuracy : 79.613473%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 160/2000 epochs spend time : 2.3964 sec / total_loss : 0.5290 correct : 23499/28705 -> 81.8638%\n",
            "test dataset : 160/2000 epochs spend time : 0.3321 sec  / total_loss : 0.5591 correct : 7180/9055 -> 79.2932%\n",
            "best epoch : 157/2000 / val accuracy : 79.613473%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 161/2000 epochs spend time : 2.3863 sec / total_loss : 0.5278 correct : 23459/28705 -> 81.7244%\n",
            "test dataset : 161/2000 epochs spend time : 0.3421 sec  / total_loss : 0.5631 correct : 7179/9055 -> 79.2822%\n",
            "best epoch : 157/2000 / val accuracy : 79.613473%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 162/2000 epochs spend time : 2.4118 sec / total_loss : 0.5241 correct : 23550/28705 -> 82.0415%\n",
            "test dataset : 162/2000 epochs spend time : 0.3365 sec  / total_loss : 0.5576 correct : 7204/9055 -> 79.5583%\n",
            "best epoch : 157/2000 / val accuracy : 79.613473%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 163/2000 epochs spend time : 2.4071 sec / total_loss : 0.5274 correct : 23391/28705 -> 81.4875%\n",
            "test dataset : 163/2000 epochs spend time : 0.3366 sec  / total_loss : 0.5590 correct : 7215/9055 -> 79.6797%\n",
            "best epoch : 163/2000 / val accuracy : 79.679735%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 164/2000 epochs spend time : 2.4049 sec / total_loss : 0.5305 correct : 23369/28705 -> 81.4109%\n",
            "test dataset : 164/2000 epochs spend time : 0.3304 sec  / total_loss : 0.5568 correct : 7164/9055 -> 79.1165%\n",
            "best epoch : 163/2000 / val accuracy : 79.679735%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 165/2000 epochs spend time : 2.3993 sec / total_loss : 0.5272 correct : 23452/28705 -> 81.7001%\n",
            "test dataset : 165/2000 epochs spend time : 0.3426 sec  / total_loss : 0.5599 correct : 7221/9055 -> 79.7460%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 166/2000 epochs spend time : 2.4151 sec / total_loss : 0.5317 correct : 23429/28705 -> 81.6199%\n",
            "test dataset : 166/2000 epochs spend time : 0.3399 sec  / total_loss : 0.5654 correct : 7217/9055 -> 79.7018%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 167/2000 epochs spend time : 2.3937 sec / total_loss : 0.5211 correct : 23539/28705 -> 82.0031%\n",
            "test dataset : 167/2000 epochs spend time : 0.3392 sec  / total_loss : 0.5588 correct : 7187/9055 -> 79.3705%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 168/2000 epochs spend time : 2.4122 sec / total_loss : 0.5236 correct : 23560/28705 -> 82.0763%\n",
            "test dataset : 168/2000 epochs spend time : 0.3376 sec  / total_loss : 0.5518 correct : 7209/9055 -> 79.6135%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 169/2000 epochs spend time : 2.3811 sec / total_loss : 0.5125 correct : 23619/28705 -> 82.2818%\n",
            "test dataset : 169/2000 epochs spend time : 0.3313 sec  / total_loss : 0.5589 correct : 7178/9055 -> 79.2711%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 170/2000 epochs spend time : 2.4133 sec / total_loss : 0.5161 correct : 23613/28705 -> 82.2609%\n",
            "test dataset : 170/2000 epochs spend time : 0.3344 sec  / total_loss : 0.5566 correct : 7188/9055 -> 79.3816%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 171/2000 epochs spend time : 2.3847 sec / total_loss : 0.5157 correct : 23553/28705 -> 82.0519%\n",
            "test dataset : 171/2000 epochs spend time : 0.3329 sec  / total_loss : 0.5520 correct : 7219/9055 -> 79.7239%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 172/2000 epochs spend time : 2.3871 sec / total_loss : 0.5108 correct : 23683/28705 -> 82.5048%\n",
            "test dataset : 172/2000 epochs spend time : 0.3349 sec  / total_loss : 0.5748 correct : 7137/9055 -> 78.8183%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 173/2000 epochs spend time : 2.4363 sec / total_loss : 0.5207 correct : 23481/28705 -> 81.8011%\n",
            "test dataset : 173/2000 epochs spend time : 0.3478 sec  / total_loss : 0.5623 correct : 7175/9055 -> 79.2380%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 174/2000 epochs spend time : 2.4395 sec / total_loss : 0.5134 correct : 23649/28705 -> 82.3863%\n",
            "test dataset : 174/2000 epochs spend time : 0.3512 sec  / total_loss : 0.5923 correct : 7083/9055 -> 78.2220%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 175/2000 epochs spend time : 2.4388 sec / total_loss : 0.5226 correct : 23485/28705 -> 81.8150%\n",
            "test dataset : 175/2000 epochs spend time : 0.3542 sec  / total_loss : 0.5671 correct : 7196/9055 -> 79.4699%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 176/2000 epochs spend time : 2.4429 sec / total_loss : 0.5263 correct : 23510/28705 -> 81.9021%\n",
            "test dataset : 176/2000 epochs spend time : 0.3465 sec  / total_loss : 0.5675 correct : 7213/9055 -> 79.6576%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 177/2000 epochs spend time : 2.3948 sec / total_loss : 0.5121 correct : 23634/28705 -> 82.3341%\n",
            "test dataset : 177/2000 epochs spend time : 0.3293 sec  / total_loss : 0.5714 correct : 7218/9055 -> 79.7129%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 178/2000 epochs spend time : 2.3768 sec / total_loss : 0.5058 correct : 23713/28705 -> 82.6093%\n",
            "test dataset : 178/2000 epochs spend time : 0.3227 sec  / total_loss : 0.5627 correct : 7195/9055 -> 79.4589%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000250\n",
            "train dataset : 179/2000 epochs spend time : 2.3722 sec / total_loss : 0.5056 correct : 23677/28705 -> 82.4839%\n",
            "test dataset : 179/2000 epochs spend time : 0.3330 sec  / total_loss : 0.5809 correct : 7170/9055 -> 79.1828%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000125\n",
            "train dataset : 180/2000 epochs spend time : 2.3941 sec / total_loss : 0.4964 correct : 23782/28705 -> 82.8497%\n",
            "test dataset : 180/2000 epochs spend time : 0.3357 sec  / total_loss : 0.5559 correct : 7221/9055 -> 79.7460%\n",
            "best epoch : 165/2000 / val accuracy : 79.745997%\n",
            "==============================\n",
            "current_lr : 0.000125\n",
            "train dataset : 181/2000 epochs spend time : 2.3906 sec / total_loss : 0.4937 correct : 23864/28705 -> 83.1353%\n",
            "test dataset : 181/2000 epochs spend time : 0.3285 sec  / total_loss : 0.5547 correct : 7253/9055 -> 80.0994%\n",
            "best epoch : 181/2000 / val accuracy : 80.099393%\n",
            "==============================\n",
            "current_lr : 0.000125\n",
            "train dataset : 182/2000 epochs spend time : 2.3924 sec / total_loss : 0.4887 correct : 23860/28705 -> 83.1214%\n",
            "test dataset : 182/2000 epochs spend time : 0.3548 sec  / total_loss : 0.5577 correct : 7218/9055 -> 79.7129%\n",
            "best epoch : 181/2000 / val accuracy : 80.099393%\n",
            "==============================\n",
            "current_lr : 0.000125\n",
            "train dataset : 183/2000 epochs spend time : 2.3953 sec / total_loss : 0.4935 correct : 23815/28705 -> 82.9646%\n",
            "test dataset : 183/2000 epochs spend time : 0.3269 sec  / total_loss : 0.5551 correct : 7262/9055 -> 80.1988%\n",
            "best epoch : 183/2000 / val accuracy : 80.198785%\n",
            "==============================\n",
            "current_lr : 0.000125\n",
            "train dataset : 184/2000 epochs spend time : 2.4049 sec / total_loss : 0.4860 correct : 23942/28705 -> 83.4071%\n",
            "test dataset : 184/2000 epochs spend time : 0.3347 sec  / total_loss : 0.5582 correct : 7230/9055 -> 79.8454%\n",
            "best epoch : 183/2000 / val accuracy : 80.198785%\n",
            "==============================\n",
            "current_lr : 0.000125\n",
            "train dataset : 185/2000 epochs spend time : 2.3924 sec / total_loss : 0.4870 correct : 23922/28705 -> 83.3374%\n",
            "test dataset : 185/2000 epochs spend time : 0.3384 sec  / total_loss : 0.5608 correct : 7236/9055 -> 79.9117%\n",
            "best epoch : 183/2000 / val accuracy : 80.198785%\n",
            "==============================\n",
            "current_lr : 0.000125\n",
            "train dataset : 186/2000 epochs spend time : 2.3882 sec / total_loss : 0.4863 correct : 23906/28705 -> 83.2817%\n",
            "test dataset : 186/2000 epochs spend time : 0.3411 sec  / total_loss : 0.5550 correct : 7247/9055 -> 80.0331%\n",
            "best epoch : 183/2000 / val accuracy : 80.198785%\n",
            "==============================\n",
            "current_lr : 0.000125\n",
            "train dataset : 187/2000 epochs spend time : 2.3944 sec / total_loss : 0.4845 correct : 23999/28705 -> 83.6056%\n",
            "test dataset : 187/2000 epochs spend time : 0.3349 sec  / total_loss : 0.5590 correct : 7240/9055 -> 79.9558%\n",
            "best epoch : 183/2000 / val accuracy : 80.198785%\n",
            "==============================\n",
            "current_lr : 0.000125\n",
            "train dataset : 188/2000 epochs spend time : 2.3843 sec / total_loss : 0.4835 correct : 23978/28705 -> 83.5325%\n",
            "test dataset : 188/2000 epochs spend time : 0.3339 sec  / total_loss : 0.5634 correct : 7259/9055 -> 80.1657%\n",
            "best epoch : 183/2000 / val accuracy : 80.198785%\n",
            "==============================\n",
            "current_lr : 0.000125\n",
            "train dataset : 189/2000 epochs spend time : 2.3880 sec / total_loss : 0.4823 correct : 23968/28705 -> 83.4976%\n",
            "test dataset : 189/2000 epochs spend time : 0.3397 sec  / total_loss : 0.5630 correct : 7255/9055 -> 80.1215%\n",
            "best epoch : 183/2000 / val accuracy : 80.198785%\n",
            "==============================\n",
            "current_lr : 0.000125\n",
            "train dataset : 190/2000 epochs spend time : 2.3836 sec / total_loss : 0.4783 correct : 23969/28705 -> 83.5011%\n",
            "test dataset : 190/2000 epochs spend time : 0.3263 sec  / total_loss : 0.5662 correct : 7210/9055 -> 79.6245%\n",
            "best epoch : 183/2000 / val accuracy : 80.198785%\n",
            "==============================\n",
            "current_lr : 0.000063\n",
            "train dataset : 191/2000 epochs spend time : 2.3773 sec / total_loss : 0.4749 correct : 24074/28705 -> 83.8669%\n",
            "test dataset : 191/2000 epochs spend time : 0.3457 sec  / total_loss : 0.5580 correct : 7273/9055 -> 80.3203%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000063\n",
            "train dataset : 192/2000 epochs spend time : 2.3829 sec / total_loss : 0.4745 correct : 24032/28705 -> 83.7206%\n",
            "test dataset : 192/2000 epochs spend time : 0.3339 sec  / total_loss : 0.5594 correct : 7257/9055 -> 80.1436%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000063\n",
            "train dataset : 193/2000 epochs spend time : 2.3843 sec / total_loss : 0.4698 correct : 24088/28705 -> 83.9157%\n",
            "test dataset : 193/2000 epochs spend time : 0.3369 sec  / total_loss : 0.5594 correct : 7270/9055 -> 80.2871%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000063\n",
            "train dataset : 194/2000 epochs spend time : 2.4115 sec / total_loss : 0.4760 correct : 24005/28705 -> 83.6265%\n",
            "test dataset : 194/2000 epochs spend time : 0.3309 sec  / total_loss : 0.5604 correct : 7252/9055 -> 80.0883%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000063\n",
            "train dataset : 195/2000 epochs spend time : 2.3962 sec / total_loss : 0.4730 correct : 24111/28705 -> 83.9958%\n",
            "test dataset : 195/2000 epochs spend time : 0.3446 sec  / total_loss : 0.5629 correct : 7261/9055 -> 80.1877%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000063\n",
            "train dataset : 196/2000 epochs spend time : 2.4041 sec / total_loss : 0.4728 correct : 24038/28705 -> 83.7415%\n",
            "test dataset : 196/2000 epochs spend time : 0.3461 sec  / total_loss : 0.5607 correct : 7243/9055 -> 79.9890%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000063\n",
            "train dataset : 197/2000 epochs spend time : 2.3921 sec / total_loss : 0.4704 correct : 24131/28705 -> 84.0655%\n",
            "test dataset : 197/2000 epochs spend time : 0.3334 sec  / total_loss : 0.5602 correct : 7256/9055 -> 80.1325%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000063\n",
            "train dataset : 198/2000 epochs spend time : 2.3945 sec / total_loss : 0.4683 correct : 24141/28705 -> 84.1003%\n",
            "test dataset : 198/2000 epochs spend time : 0.3303 sec  / total_loss : 0.5624 correct : 7261/9055 -> 80.1877%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000063\n",
            "train dataset : 199/2000 epochs spend time : 2.3623 sec / total_loss : 0.4715 correct : 24125/28705 -> 84.0446%\n",
            "test dataset : 199/2000 epochs spend time : 0.3258 sec  / total_loss : 0.5607 correct : 7269/9055 -> 80.2761%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000063\n",
            "train dataset : 200/2000 epochs spend time : 2.3892 sec / total_loss : 0.4701 correct : 24104/28705 -> 83.9714%\n",
            "test dataset : 200/2000 epochs spend time : 0.3301 sec  / total_loss : 0.5673 correct : 7241/9055 -> 79.9669%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000063\n",
            "train dataset : 201/2000 epochs spend time : 2.3914 sec / total_loss : 0.4699 correct : 24127/28705 -> 84.0516%\n",
            "test dataset : 201/2000 epochs spend time : 0.3254 sec  / total_loss : 0.5632 correct : 7264/9055 -> 80.2209%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000031\n",
            "train dataset : 202/2000 epochs spend time : 2.3810 sec / total_loss : 0.4658 correct : 24164/28705 -> 84.1805%\n",
            "test dataset : 202/2000 epochs spend time : 0.3300 sec  / total_loss : 0.5626 correct : 7270/9055 -> 80.2871%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000031\n",
            "train dataset : 203/2000 epochs spend time : 2.3814 sec / total_loss : 0.4639 correct : 24160/28705 -> 84.1665%\n",
            "test dataset : 203/2000 epochs spend time : 0.3516 sec  / total_loss : 0.5626 correct : 7265/9055 -> 80.2319%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000031\n",
            "train dataset : 204/2000 epochs spend time : 2.3840 sec / total_loss : 0.4648 correct : 24215/28705 -> 84.3581%\n",
            "test dataset : 204/2000 epochs spend time : 0.3287 sec  / total_loss : 0.5624 correct : 7265/9055 -> 80.2319%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000031\n",
            "train dataset : 205/2000 epochs spend time : 2.3787 sec / total_loss : 0.4637 correct : 24178/28705 -> 84.2292%\n",
            "test dataset : 205/2000 epochs spend time : 0.3325 sec  / total_loss : 0.5623 correct : 7272/9055 -> 80.3092%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000031\n",
            "train dataset : 206/2000 epochs spend time : 2.3949 sec / total_loss : 0.4650 correct : 24226/28705 -> 84.3964%\n",
            "test dataset : 206/2000 epochs spend time : 0.3245 sec  / total_loss : 0.5629 correct : 7266/9055 -> 80.2430%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000031\n",
            "train dataset : 207/2000 epochs spend time : 2.4065 sec / total_loss : 0.4621 correct : 24222/28705 -> 84.3825%\n",
            "test dataset : 207/2000 epochs spend time : 0.3370 sec  / total_loss : 0.5641 correct : 7259/9055 -> 80.1657%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000031\n",
            "train dataset : 208/2000 epochs spend time : 2.3714 sec / total_loss : 0.4646 correct : 24189/28705 -> 84.2675%\n",
            "test dataset : 208/2000 epochs spend time : 0.3378 sec  / total_loss : 0.5626 correct : 7257/9055 -> 80.1436%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000031\n",
            "train dataset : 209/2000 epochs spend time : 2.3798 sec / total_loss : 0.4624 correct : 24180/28705 -> 84.2362%\n",
            "test dataset : 209/2000 epochs spend time : 0.3292 sec  / total_loss : 0.5649 correct : 7256/9055 -> 80.1325%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000031\n",
            "train dataset : 210/2000 epochs spend time : 2.3823 sec / total_loss : 0.4626 correct : 24204/28705 -> 84.3198%\n",
            "test dataset : 210/2000 epochs spend time : 0.3357 sec  / total_loss : 0.5633 correct : 7271/9055 -> 80.2982%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000031\n",
            "train dataset : 211/2000 epochs spend time : 2.3701 sec / total_loss : 0.4591 correct : 24210/28705 -> 84.3407%\n",
            "test dataset : 211/2000 epochs spend time : 0.3391 sec  / total_loss : 0.5641 correct : 7267/9055 -> 80.2540%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000031\n",
            "train dataset : 212/2000 epochs spend time : 2.3831 sec / total_loss : 0.4596 correct : 24235/28705 -> 84.4278%\n",
            "test dataset : 212/2000 epochs spend time : 0.3283 sec  / total_loss : 0.5644 correct : 7266/9055 -> 80.2430%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000016\n",
            "train dataset : 213/2000 epochs spend time : 2.3752 sec / total_loss : 0.4609 correct : 24271/28705 -> 84.5532%\n",
            "test dataset : 213/2000 epochs spend time : 0.3313 sec  / total_loss : 0.5644 correct : 7266/9055 -> 80.2430%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000016\n",
            "train dataset : 214/2000 epochs spend time : 2.3966 sec / total_loss : 0.4580 correct : 24259/28705 -> 84.5114%\n",
            "test dataset : 214/2000 epochs spend time : 0.3258 sec  / total_loss : 0.5642 correct : 7266/9055 -> 80.2430%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000016\n",
            "train dataset : 215/2000 epochs spend time : 2.3764 sec / total_loss : 0.4616 correct : 24250/28705 -> 84.4801%\n",
            "test dataset : 215/2000 epochs spend time : 0.3346 sec  / total_loss : 0.5646 correct : 7267/9055 -> 80.2540%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000016\n",
            "train dataset : 216/2000 epochs spend time : 2.3864 sec / total_loss : 0.4624 correct : 24240/28705 -> 84.4452%\n",
            "test dataset : 216/2000 epochs spend time : 0.3253 sec  / total_loss : 0.5639 correct : 7267/9055 -> 80.2540%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000016\n",
            "train dataset : 217/2000 epochs spend time : 2.3876 sec / total_loss : 0.4599 correct : 24256/28705 -> 84.5010%\n",
            "test dataset : 217/2000 epochs spend time : 0.3282 sec  / total_loss : 0.5643 correct : 7268/9055 -> 80.2650%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000016\n",
            "train dataset : 218/2000 epochs spend time : 2.3839 sec / total_loss : 0.4590 correct : 24252/28705 -> 84.4870%\n",
            "test dataset : 218/2000 epochs spend time : 0.3303 sec  / total_loss : 0.5641 correct : 7269/9055 -> 80.2761%\n",
            "best epoch : 191/2000 / val accuracy : 80.320265%\n",
            "==============================\n",
            "current_lr : 0.000016\n",
            "train dataset : 219/2000 epochs spend time : 2.3768 sec / total_loss : 0.4608 correct : 24289/28705 -> 84.6159%\n",
            "test dataset : 219/2000 epochs spend time : 0.3239 sec  / total_loss : 0.5642 correct : 7276/9055 -> 80.3534%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000016\n",
            "train dataset : 220/2000 epochs spend time : 2.3970 sec / total_loss : 0.4555 correct : 24266/28705 -> 84.5358%\n",
            "test dataset : 220/2000 epochs spend time : 0.3259 sec  / total_loss : 0.5650 correct : 7268/9055 -> 80.2650%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000016\n",
            "train dataset : 221/2000 epochs spend time : 2.3828 sec / total_loss : 0.4591 correct : 24271/28705 -> 84.5532%\n",
            "test dataset : 221/2000 epochs spend time : 0.3373 sec  / total_loss : 0.5649 correct : 7272/9055 -> 80.3092%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000016\n",
            "train dataset : 222/2000 epochs spend time : 2.3790 sec / total_loss : 0.4578 correct : 24243/28705 -> 84.4557%\n",
            "test dataset : 222/2000 epochs spend time : 0.3238 sec  / total_loss : 0.5650 correct : 7269/9055 -> 80.2761%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000016\n",
            "train dataset : 223/2000 epochs spend time : 2.3735 sec / total_loss : 0.4586 correct : 24250/28705 -> 84.4801%\n",
            "test dataset : 223/2000 epochs spend time : 0.3407 sec  / total_loss : 0.5645 correct : 7271/9055 -> 80.2982%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000008\n",
            "train dataset : 224/2000 epochs spend time : 2.3978 sec / total_loss : 0.4584 correct : 24264/28705 -> 84.5288%\n",
            "test dataset : 224/2000 epochs spend time : 0.3447 sec  / total_loss : 0.5645 correct : 7273/9055 -> 80.3203%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000008\n",
            "train dataset : 225/2000 epochs spend time : 2.3957 sec / total_loss : 0.4605 correct : 24243/28705 -> 84.4557%\n",
            "test dataset : 225/2000 epochs spend time : 0.3288 sec  / total_loss : 0.5647 correct : 7268/9055 -> 80.2650%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000008\n",
            "train dataset : 226/2000 epochs spend time : 2.3940 sec / total_loss : 0.4558 correct : 24283/28705 -> 84.5950%\n",
            "test dataset : 226/2000 epochs spend time : 0.3316 sec  / total_loss : 0.5652 correct : 7272/9055 -> 80.3092%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000008\n",
            "train dataset : 227/2000 epochs spend time : 2.4005 sec / total_loss : 0.4570 correct : 24280/28705 -> 84.5846%\n",
            "test dataset : 227/2000 epochs spend time : 0.3429 sec  / total_loss : 0.5649 correct : 7270/9055 -> 80.2871%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000008\n",
            "train dataset : 228/2000 epochs spend time : 2.3625 sec / total_loss : 0.4619 correct : 24270/28705 -> 84.5497%\n",
            "test dataset : 228/2000 epochs spend time : 0.3424 sec  / total_loss : 0.5648 correct : 7269/9055 -> 80.2761%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000008\n",
            "train dataset : 229/2000 epochs spend time : 2.3868 sec / total_loss : 0.4580 correct : 24265/28705 -> 84.5323%\n",
            "test dataset : 229/2000 epochs spend time : 0.3382 sec  / total_loss : 0.5651 correct : 7272/9055 -> 80.3092%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000008\n",
            "train dataset : 230/2000 epochs spend time : 2.3584 sec / total_loss : 0.4584 correct : 24251/28705 -> 84.4835%\n",
            "test dataset : 230/2000 epochs spend time : 0.3389 sec  / total_loss : 0.5651 correct : 7274/9055 -> 80.3313%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000008\n",
            "train dataset : 231/2000 epochs spend time : 2.3788 sec / total_loss : 0.4588 correct : 24294/28705 -> 84.6333%\n",
            "test dataset : 231/2000 epochs spend time : 0.3335 sec  / total_loss : 0.5651 correct : 7273/9055 -> 80.3203%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000008\n",
            "train dataset : 232/2000 epochs spend time : 2.3849 sec / total_loss : 0.4601 correct : 24302/28705 -> 84.6612%\n",
            "test dataset : 232/2000 epochs spend time : 0.3311 sec  / total_loss : 0.5653 correct : 7271/9055 -> 80.2982%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000008\n",
            "train dataset : 233/2000 epochs spend time : 2.3992 sec / total_loss : 0.4568 correct : 24291/28705 -> 84.6229%\n",
            "test dataset : 233/2000 epochs spend time : 0.3269 sec  / total_loss : 0.5652 correct : 7269/9055 -> 80.2761%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000008\n",
            "train dataset : 234/2000 epochs spend time : 2.3659 sec / total_loss : 0.4570 correct : 24264/28705 -> 84.5288%\n",
            "test dataset : 234/2000 epochs spend time : 0.3351 sec  / total_loss : 0.5649 correct : 7272/9055 -> 80.3092%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000004\n",
            "train dataset : 235/2000 epochs spend time : 2.3874 sec / total_loss : 0.4560 correct : 24247/28705 -> 84.4696%\n",
            "test dataset : 235/2000 epochs spend time : 0.3283 sec  / total_loss : 0.5649 correct : 7271/9055 -> 80.2982%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000004\n",
            "train dataset : 236/2000 epochs spend time : 2.3680 sec / total_loss : 0.4567 correct : 24237/28705 -> 84.4348%\n",
            "test dataset : 236/2000 epochs spend time : 0.3365 sec  / total_loss : 0.5651 correct : 7272/9055 -> 80.3092%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000004\n",
            "train dataset : 237/2000 epochs spend time : 2.3698 sec / total_loss : 0.4576 correct : 24304/28705 -> 84.6682%\n",
            "test dataset : 237/2000 epochs spend time : 0.3326 sec  / total_loss : 0.5652 correct : 7271/9055 -> 80.2982%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000004\n",
            "train dataset : 238/2000 epochs spend time : 2.3787 sec / total_loss : 0.4573 correct : 24285/28705 -> 84.6020%\n",
            "test dataset : 238/2000 epochs spend time : 0.3248 sec  / total_loss : 0.5651 correct : 7271/9055 -> 80.2982%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000004\n",
            "train dataset : 239/2000 epochs spend time : 2.3548 sec / total_loss : 0.4545 correct : 24278/28705 -> 84.5776%\n",
            "test dataset : 239/2000 epochs spend time : 0.3215 sec  / total_loss : 0.5653 correct : 7271/9055 -> 80.2982%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000004\n",
            "train dataset : 240/2000 epochs spend time : 2.3861 sec / total_loss : 0.4581 correct : 24265/28705 -> 84.5323%\n",
            "test dataset : 240/2000 epochs spend time : 0.3305 sec  / total_loss : 0.5652 correct : 7273/9055 -> 80.3203%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000004\n",
            "train dataset : 241/2000 epochs spend time : 2.3564 sec / total_loss : 0.4558 correct : 24260/28705 -> 84.5149%\n",
            "test dataset : 241/2000 epochs spend time : 0.3191 sec  / total_loss : 0.5653 correct : 7269/9055 -> 80.2761%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000004\n",
            "train dataset : 242/2000 epochs spend time : 2.3795 sec / total_loss : 0.4560 correct : 24282/28705 -> 84.5915%\n",
            "test dataset : 242/2000 epochs spend time : 0.3341 sec  / total_loss : 0.5652 correct : 7270/9055 -> 80.2871%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000004\n",
            "train dataset : 243/2000 epochs spend time : 2.3696 sec / total_loss : 0.4569 correct : 24277/28705 -> 84.5741%\n",
            "test dataset : 243/2000 epochs spend time : 0.3251 sec  / total_loss : 0.5654 correct : 7271/9055 -> 80.2982%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000004\n",
            "train dataset : 244/2000 epochs spend time : 2.3726 sec / total_loss : 0.4554 correct : 24326/28705 -> 84.7448%\n",
            "test dataset : 244/2000 epochs spend time : 0.3284 sec  / total_loss : 0.5653 correct : 7269/9055 -> 80.2761%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000004\n",
            "train dataset : 245/2000 epochs spend time : 2.3687 sec / total_loss : 0.4567 correct : 24318/28705 -> 84.7169%\n",
            "test dataset : 245/2000 epochs spend time : 0.3246 sec  / total_loss : 0.5653 correct : 7272/9055 -> 80.3092%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000002\n",
            "train dataset : 246/2000 epochs spend time : 2.3805 sec / total_loss : 0.4560 correct : 24235/28705 -> 84.4278%\n",
            "test dataset : 246/2000 epochs spend time : 0.3395 sec  / total_loss : 0.5653 correct : 7270/9055 -> 80.2871%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000002\n",
            "train dataset : 247/2000 epochs spend time : 2.3653 sec / total_loss : 0.4597 correct : 24295/28705 -> 84.6368%\n",
            "test dataset : 247/2000 epochs spend time : 0.3237 sec  / total_loss : 0.5653 correct : 7271/9055 -> 80.2982%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000002\n",
            "train dataset : 248/2000 epochs spend time : 2.3864 sec / total_loss : 0.4573 correct : 24274/28705 -> 84.5637%\n",
            "test dataset : 248/2000 epochs spend time : 0.3387 sec  / total_loss : 0.5653 correct : 7273/9055 -> 80.3203%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000002\n",
            "train dataset : 249/2000 epochs spend time : 2.3692 sec / total_loss : 0.4536 correct : 24340/28705 -> 84.7936%\n",
            "test dataset : 249/2000 epochs spend time : 0.3389 sec  / total_loss : 0.5652 correct : 7271/9055 -> 80.2982%\n",
            "best epoch : 219/2000 / val accuracy : 80.353396%\n",
            "==============================\n",
            "current_lr : 0.000002\n",
            "train dataset : 250/2000 epochs spend time : 2.3931 sec / total_loss : 0.4571 correct : 24269/28705 -> 84.5462%\n",
            "test dataset : 250/2000 epochs spend time : 0.3251 sec  / total_loss : 0.5653 correct : 7269/9055 -> 80.2761%\n",
            "Early Stopping\n",
            "best epoch : 219/2000 / accuracy : 80.353396%\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCE73qoRBUC2"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    }
  ]
}